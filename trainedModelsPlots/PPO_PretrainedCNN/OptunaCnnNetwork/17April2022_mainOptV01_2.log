Script started on 2022-04-17 21:56:55-04:00 [TERM="xterm-256color" TTY="/dev/pts/1" COLUMNS="203" LINES="55"]
bash: devel/setup.bash: No such file or directory
]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew/17April2022[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew/17April2022[00m$ cd ..
]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ conda activate rl_env
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ ls
[0m[01;34m11April2022[0m  [01;34m17April2022[0m       customCnn_V02.py   mainFull_V00.py  mainOpt_V01.py   optimize_V02.py    pandareachdepth.py     pickPlaceVectOptV01.py  register.py  [01;34mtmpTestMulti[0m
[01;34m13April2022[0m  [01;34m6April2022[0m        [01;34mimages[0m             mainFull_V01.py  mainOpt_V02.py   optunaCust_V01.py  pandaWrapperBW_D_0.py  PPANDPUSH_VECT.py       timer.py     [01;34mvideos[0m
[01;34m14April2022[0m  check             linearSchedule.py  mainFull_V02.py  multiCompare.py  optunaCust_V02.py  pandaWrapperBW.py      pybulletCust.py         [01;34mtmp[0m
[01;34m16April2022[0m  customCnn_V01.py  [01;34mlogs[0m               mainMulti.py     optimize_V01.py  pandaCust.py       pandaWrapper.py        [01;34m__pycache__[0m             [01;34mtmpMulti[0m
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ python3 main_[K[KnFull_V02.py 
pybullet build time: Dec  1 2021 18:34:28
plotly:  5.6.0
optuna:  2.10.0
_XSERVTransSocketUNIXCreateListener: ...SocketCreateListener() failed
_XSERVTransMakeAllCOTSServerListeners: server already running
(EE) 
Fatal server error:
(EE) Cannot establish any listening sockets - Make sure an X server isn't already running(EE) 
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/googlenet.py:46: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/inception.py:44: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
plotly:  5.6.0
optuna:  2.10.0
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
kwargs:  {'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'gamma': 0.992601496741308, 'gae_lambda': 0.8789552297223628, 'learning_rate': 0.0001678993231767122, 'ent_coef': 1e-06, 'vf_coef': 0.75, 'clip_range': 0.075, 'max_grad_norm': 0.5, 'batch_size': 256, 'n_steps': 2048, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 128}}}
n_envs:  4
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
Traceback (most recent call last):
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/mainFull_V02.py", line 212, in <module>
    model.learn(total_timesteps=int(OPTIMIZED_N_TIMESTEPS), callback=callback)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py", line 299, in learn
    return super(PPO, self).learn(
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 250, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 169, in collect_rollouts
    actions, values, log_probs = self.policy.forward(obs_tensor)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/policies.py", line 589, in forward
    latent_pi, latent_vf = self.mlp_extractor(features)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1111, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/torch_layers.py", line 228, in forward
    return self.policy_net(shared_latent), self.value_net(shared_latent)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1111, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/container.py", line 139, in forward
    input = module(input)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1111, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/linear.py", line 103, in forward
    return F.linear(input, self.weight, self.bias)
RuntimeError: mat1 and mat2 shapes cannot be multiplied (4x1000 and 128x128)
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ python3 mainFull_V02.py 
pybullet build time: Dec  1 2021 18:34:28
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/googlenet.py:46: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/inception.py:44: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
plotly:  5.6.0
optuna:  2.10.0
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
kwargs:  {'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'gamma': 0.992601496741308, 'gae_lambda': 0.8789552297223628, 'learning_rate': 0.0001678993231767122, 'ent_coef': 1e-06, 'vf_coef': 0.75, 'clip_range': 0.075, 'max_grad_norm': 0.5, 'batch_size': 256, 'n_steps': 2048, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
Num timesteps: 8000
Best mean reward: -inf - Last mean reward per episode: -11.99
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ python3 mainFull_V02.py 
pybullet build time: Dec  1 2021 18:34:28
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/googlenet.py:46: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/inception.py:44: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
plotly:  5.6.0
optuna:  2.10.0
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
kwargs:  {'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'gamma': 0.992601496741308, 'gae_lambda': 0.8789552297223628, 'learning_rate': 0.0001678993231767122, 'ent_coef': 1e-06, 'vf_coef': 0.75, 'clip_range': 0.075, 'max_grad_norm': 0.5, 'batch_size': 256, 'n_steps': 2048, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 1        |
|    time_elapsed    | 171      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.6         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 2             |
|    time_elapsed         | 407           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00034947396 |
|    clip_fraction        | 0.0276        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.00127       |
|    learning_rate        | 0.000168      |
|    loss                 | 0.352         |
|    n_updates            | 11            |
|    policy_gradient_loss | -6.28e-05     |
|    std                  | 0.998         |
|    value_loss           | 0.503         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 3            |
|    time_elapsed         | 642          |
|    total_timesteps      | 24576        |
| train/                  |              |
|    approx_kl            | 0.0006688775 |
|    clip_fraction        | 0.0541       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.00206     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.379        |
|    n_updates            | 22           |
|    policy_gradient_loss | -0.00128     |
|    std                  | 0.997        |
|    value_loss           | 0.673        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 4             |
|    time_elapsed         | 880           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00058195344 |
|    clip_fraction        | 0.0278        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.24         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.38          |
|    n_updates            | 33            |
|    policy_gradient_loss | -0.000484     |
|    std                  | 0.994         |
|    value_loss           | 0.623         |
-------------------------------------------
Num timesteps: 40000
Best mean reward: -inf - Last mean reward per episode: -12.44
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 5            |
|    time_elapsed         | 1118         |
|    total_timesteps      | 40960        |
| train/                  |              |
|    approx_kl            | 0.0008150751 |
|    clip_fraction        | 0.0537       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 2.86e-06     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.422        |
|    n_updates            | 44           |
|    policy_gradient_loss | -0.00122     |
|    std                  | 0.992        |
|    value_loss           | 0.566        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 6             |
|    time_elapsed         | 1355          |
|    total_timesteps      | 49152         |
| train/                  |               |
|    approx_kl            | 0.00038920846 |
|    clip_fraction        | 0.022         |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.23         |
|    explained_variance   | 6.38e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.347         |
|    n_updates            | 55            |
|    policy_gradient_loss | -0.000402     |
|    std                  | 0.993         |
|    value_loss           | 0.504         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 7             |
|    time_elapsed         | 1589          |
|    total_timesteps      | 57344         |
| train/                  |               |
|    approx_kl            | 0.00071608165 |
|    clip_fraction        | 0.0418        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.23         |
|    explained_variance   | 2.74e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.316         |
|    n_updates            | 66            |
|    policy_gradient_loss | -0.00106      |
|    std                  | 0.99          |
|    value_loss           | 0.494         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 8            |
|    time_elapsed         | 1826         |
|    total_timesteps      | 65536        |
| train/                  |              |
|    approx_kl            | 0.0006743954 |
|    clip_fraction        | 0.0426       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | -3.81e-06    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.369        |
|    n_updates            | 77           |
|    policy_gradient_loss | -0.00108     |
|    std                  | 0.991        |
|    value_loss           | 0.53         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.1         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 9             |
|    time_elapsed         | 2063          |
|    total_timesteps      | 73728         |
| train/                  |               |
|    approx_kl            | 0.00060052704 |
|    clip_fraction        | 0.0392        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.22         |
|    explained_variance   | -5.96e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.276         |
|    n_updates            | 88            |
|    policy_gradient_loss | -0.00117      |
|    std                  | 0.986         |
|    value_loss           | 0.476         |
-------------------------------------------
Num timesteps: 80000
Best mean reward: -12.44 - Last mean reward per episode: -11.57
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 10           |
|    time_elapsed         | 2303         |
|    total_timesteps      | 81920        |
| train/                  |              |
|    approx_kl            | 0.0006510065 |
|    clip_fraction        | 0.0316       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.21        |
|    explained_variance   | -1.43e-06    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.308        |
|    n_updates            | 99           |
|    policy_gradient_loss | -0.000818    |
|    std                  | 0.983        |
|    value_loss           | 0.477        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 11            |
|    time_elapsed         | 2537          |
|    total_timesteps      | 90112         |
| train/                  |               |
|    approx_kl            | 0.00038464146 |
|    clip_fraction        | 0.0109        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.2          |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.313         |
|    n_updates            | 110           |
|    policy_gradient_loss | -7.42e-05     |
|    std                  | 0.98          |
|    value_loss           | 0.46          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 12            |
|    time_elapsed         | 2775          |
|    total_timesteps      | 98304         |
| train/                  |               |
|    approx_kl            | 0.00047325017 |
|    clip_fraction        | 0.0226        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.19         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.353         |
|    n_updates            | 121           |
|    policy_gradient_loss | -0.00014      |
|    std                  | 0.979         |
|    value_loss           | 0.45          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 13            |
|    time_elapsed         | 3014          |
|    total_timesteps      | 106496        |
| train/                  |               |
|    approx_kl            | 0.00049471273 |
|    clip_fraction        | 0.0191        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.19         |
|    explained_variance   | -3.46e-06     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.245         |
|    n_updates            | 132           |
|    policy_gradient_loss | -0.000241     |
|    std                  | 0.976         |
|    value_loss           | 0.408         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.6         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 14            |
|    time_elapsed         | 3251          |
|    total_timesteps      | 114688        |
| train/                  |               |
|    approx_kl            | 0.00043125972 |
|    clip_fraction        | 0.0186        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.18         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.279         |
|    n_updates            | 143           |
|    policy_gradient_loss | -0.000247     |
|    std                  | 0.973         |
|    value_loss           | 0.375         |
-------------------------------------------
Num timesteps: 120000
Best mean reward: -11.57 - Last mean reward per episode: -11.87
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.1         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 15            |
|    time_elapsed         | 3490          |
|    total_timesteps      | 122880        |
| train/                  |               |
|    approx_kl            | 0.00059452315 |
|    clip_fraction        | 0.0256        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.17         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.32          |
|    n_updates            | 154           |
|    policy_gradient_loss | -0.000265     |
|    std                  | 0.968         |
|    value_loss           | 0.414         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 16           |
|    time_elapsed         | 3726         |
|    total_timesteps      | 131072       |
| train/                  |              |
|    approx_kl            | 0.0006289977 |
|    clip_fraction        | 0.0356       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.16        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.259        |
|    n_updates            | 165          |
|    policy_gradient_loss | -0.000776    |
|    std                  | 0.969        |
|    value_loss           | 0.4          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 17            |
|    time_elapsed         | 3965          |
|    total_timesteps      | 139264        |
| train/                  |               |
|    approx_kl            | 0.00056020974 |
|    clip_fraction        | 0.0297        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.16         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.285         |
|    n_updates            | 176           |
|    policy_gradient_loss | -0.000288     |
|    std                  | 0.966         |
|    value_loss           | 0.411         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 18            |
|    time_elapsed         | 4203          |
|    total_timesteps      | 147456        |
| train/                  |               |
|    approx_kl            | 0.00044621178 |
|    clip_fraction        | 0.0162        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.15         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.384         |
|    n_updates            | 187           |
|    policy_gradient_loss | -0.000221     |
|    std                  | 0.962         |
|    value_loss           | 0.406         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 19           |
|    time_elapsed         | 4441         |
|    total_timesteps      | 155648       |
| train/                  |              |
|    approx_kl            | 0.0006307586 |
|    clip_fraction        | 0.0292       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.14        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.276        |
|    n_updates            | 198          |
|    policy_gradient_loss | -0.000549    |
|    std                  | 0.961        |
|    value_loss           | 0.407        |
------------------------------------------
Num timesteps: 160000
Best mean reward: -11.57 - Last mean reward per episode: -11.31
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 20            |
|    time_elapsed         | 4682          |
|    total_timesteps      | 163840        |
| train/                  |               |
|    approx_kl            | 0.00036452635 |
|    clip_fraction        | 0.0088        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.14         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.255         |
|    n_updates            | 209           |
|    policy_gradient_loss | -0.000104     |
|    std                  | 0.96          |
|    value_loss           | 0.352         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 21            |
|    time_elapsed         | 4917          |
|    total_timesteps      | 172032        |
| train/                  |               |
|    approx_kl            | 0.00071207376 |
|    clip_fraction        | 0.0342        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.13         |
|    explained_variance   | -7.75e-06     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.259         |
|    n_updates            | 220           |
|    policy_gradient_loss | -0.000731     |
|    std                  | 0.958         |
|    value_loss           | 0.394         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 22            |
|    time_elapsed         | 5151          |
|    total_timesteps      | 180224        |
| train/                  |               |
|    approx_kl            | 0.00071119826 |
|    clip_fraction        | 0.0426        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.12         |
|    explained_variance   | 2.56e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.265         |
|    n_updates            | 231           |
|    policy_gradient_loss | -0.000834     |
|    std                  | 0.957         |
|    value_loss           | 0.355         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 23            |
|    time_elapsed         | 5386          |
|    total_timesteps      | 188416        |
| train/                  |               |
|    approx_kl            | 0.00036739785 |
|    clip_fraction        | 0.0165        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.13         |
|    explained_variance   | 1.26e-05      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.218         |
|    n_updates            | 242           |
|    policy_gradient_loss | -0.000173     |
|    std                  | 0.96          |
|    value_loss           | 0.368         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 24           |
|    time_elapsed         | 5619         |
|    total_timesteps      | 196608       |
| train/                  |              |
|    approx_kl            | 0.0005515025 |
|    clip_fraction        | 0.019        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.13        |
|    explained_variance   | 4.47e-06     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.329        |
|    n_updates            | 253          |
|    policy_gradient_loss | -0.000343    |
|    std                  | 0.961        |
|    value_loss           | 0.42         |
------------------------------------------
Num timesteps: 200000
Best mean reward: -11.31 - Last mean reward per episode: -11.53
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 25           |
|    time_elapsed         | 5854         |
|    total_timesteps      | 204800       |
| train/                  |              |
|    approx_kl            | 0.0006040563 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.14        |
|    explained_variance   | -2.38e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.35         |
|    n_updates            | 264          |
|    policy_gradient_loss | -0.000541    |
|    std                  | 0.961        |
|    value_loss           | 0.472        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 26           |
|    time_elapsed         | 6092         |
|    total_timesteps      | 212992       |
| train/                  |              |
|    approx_kl            | 0.0005139386 |
|    clip_fraction        | 0.0288       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.13        |
|    explained_variance   | -1.19e-06    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.315        |
|    n_updates            | 275          |
|    policy_gradient_loss | -0.000418    |
|    std                  | 0.961        |
|    value_loss           | 0.422        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 27           |
|    time_elapsed         | 6329         |
|    total_timesteps      | 221184       |
| train/                  |              |
|    approx_kl            | 0.0005009228 |
|    clip_fraction        | 0.027        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.13        |
|    explained_variance   | 1.51e-05     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.251        |
|    n_updates            | 286          |
|    policy_gradient_loss | -0.000462    |
|    std                  | 0.958        |
|    value_loss           | 0.37         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 28            |
|    time_elapsed         | 6561          |
|    total_timesteps      | 229376        |
| train/                  |               |
|    approx_kl            | 0.00069585815 |
|    clip_fraction        | 0.0405        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.12         |
|    explained_variance   | 3.58e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.28          |
|    n_updates            | 297           |
|    policy_gradient_loss | -0.00124      |
|    std                  | 0.956         |
|    value_loss           | 0.407         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 29            |
|    time_elapsed         | 6802          |
|    total_timesteps      | 237568        |
| train/                  |               |
|    approx_kl            | 0.00055024726 |
|    clip_fraction        | 0.0235        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.12         |
|    explained_variance   | 2.09e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.259         |
|    n_updates            | 308           |
|    policy_gradient_loss | -0.000386     |
|    std                  | 0.955         |
|    value_loss           | 0.362         |
-------------------------------------------
Num timesteps: 240000
Best mean reward: -11.31 - Last mean reward per episode: -11.80
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 30            |
|    time_elapsed         | 7044          |
|    total_timesteps      | 245760        |
| train/                  |               |
|    approx_kl            | 0.00053053186 |
|    clip_fraction        | 0.0248        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.12         |
|    explained_variance   | 1.34e-05      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.213         |
|    n_updates            | 319           |
|    policy_gradient_loss | -0.000518     |
|    std                  | 0.955         |
|    value_loss           | 0.337         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 31           |
|    time_elapsed         | 7280         |
|    total_timesteps      | 253952       |
| train/                  |              |
|    approx_kl            | 0.0005973595 |
|    clip_fraction        | 0.0331       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.12        |
|    explained_variance   | 1.43e-06     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.269        |
|    n_updates            | 330          |
|    policy_gradient_loss | -0.000726    |
|    std                  | 0.956        |
|    value_loss           | 0.343        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -11.7       |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 32          |
|    time_elapsed         | 7518        |
|    total_timesteps      | 262144      |
| train/                  |             |
|    approx_kl            | 0.000507833 |
|    clip_fraction        | 0.0173      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.12       |
|    explained_variance   | 1.79e-05    |
|    learning_rate        | 0.000168    |
|    loss                 | 0.253       |
|    n_updates            | 341         |
|    policy_gradient_loss | -0.000234   |
|    std                  | 0.956       |
|    value_loss           | 0.358       |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 33            |
|    time_elapsed         | 7755          |
|    total_timesteps      | 270336        |
| train/                  |               |
|    approx_kl            | 0.00045361536 |
|    clip_fraction        | 0.0209        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.11         |
|    explained_variance   | 3.81e-06      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.226         |
|    n_updates            | 352           |
|    policy_gradient_loss | -0.000575     |
|    std                  | 0.953         |
|    value_loss           | 0.316         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 34           |
|    time_elapsed         | 7994         |
|    total_timesteps      | 278528       |
| train/                  |              |
|    approx_kl            | 0.0008392492 |
|    clip_fraction        | 0.0374       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.1         |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.224        |
|    n_updates            | 363          |
|    policy_gradient_loss | -0.00075     |
|    std                  | 0.948        |
|    value_loss           | 0.348        |
------------------------------------------
Num timesteps: 280000
Best mean reward: -11.31 - Last mean reward per episode: -11.92
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 35            |
|    time_elapsed         | 8229          |
|    total_timesteps      | 286720        |
| train/                  |               |
|    approx_kl            | 0.00062731793 |
|    clip_fraction        | 0.0309        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.09         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.326         |
|    n_updates            | 374           |
|    policy_gradient_loss | -0.000767     |
|    std                  | 0.945         |
|    value_loss           | 0.384         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 36            |
|    time_elapsed         | 8464          |
|    total_timesteps      | 294912        |
| train/                  |               |
|    approx_kl            | 0.00030632268 |
|    clip_fraction        | 0.0185        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.08         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.294         |
|    n_updates            | 385           |
|    policy_gradient_loss | 2e-05         |
|    std                  | 0.944         |
|    value_loss           | 0.423         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 37            |
|    time_elapsed         | 8698          |
|    total_timesteps      | 303104        |
| train/                  |               |
|    approx_kl            | 0.00030013997 |
|    clip_fraction        | 0.0145        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.08         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.251         |
|    n_updates            | 396           |
|    policy_gradient_loss | -0.000139     |
|    std                  | 0.947         |
|    value_loss           | 0.388         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 38           |
|    time_elapsed         | 8936         |
|    total_timesteps      | 311296       |
| train/                  |              |
|    approx_kl            | 0.0004473759 |
|    clip_fraction        | 0.0138       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.09        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.235        |
|    n_updates            | 407          |
|    policy_gradient_loss | -4.13e-05    |
|    std                  | 0.948        |
|    value_loss           | 0.331        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 39           |
|    time_elapsed         | 9172         |
|    total_timesteps      | 319488       |
| train/                  |              |
|    approx_kl            | 0.0006858876 |
|    clip_fraction        | 0.0289       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.1         |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.288        |
|    n_updates            | 418          |
|    policy_gradient_loss | -0.000682    |
|    std                  | 0.952        |
|    value_loss           | 0.388        |
------------------------------------------
Num timesteps: 320000
Best mean reward: -11.31 - Last mean reward per episode: -11.28
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 40            |
|    time_elapsed         | 9408          |
|    total_timesteps      | 327680        |
| train/                  |               |
|    approx_kl            | 0.00040049752 |
|    clip_fraction        | 0.0165        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.1          |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.246         |
|    n_updates            | 429           |
|    policy_gradient_loss | -0.000136     |
|    std                  | 0.949         |
|    value_loss           | 0.345         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 41           |
|    time_elapsed         | 9644         |
|    total_timesteps      | 335872       |
| train/                  |              |
|    approx_kl            | 0.0004731132 |
|    clip_fraction        | 0.0263       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.08        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.273        |
|    n_updates            | 440          |
|    policy_gradient_loss | -0.00061     |
|    std                  | 0.945        |
|    value_loss           | 0.377        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 42           |
|    time_elapsed         | 9879         |
|    total_timesteps      | 344064       |
| train/                  |              |
|    approx_kl            | 0.0005946219 |
|    clip_fraction        | 0.0189       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.07        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.28         |
|    n_updates            | 451          |
|    policy_gradient_loss | -0.000292    |
|    std                  | 0.942        |
|    value_loss           | 0.394        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 43           |
|    time_elapsed         | 10116        |
|    total_timesteps      | 352256       |
| train/                  |              |
|    approx_kl            | 0.0005759194 |
|    clip_fraction        | 0.0273       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.07        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.275        |
|    n_updates            | 462          |
|    policy_gradient_loss | -0.000583    |
|    std                  | 0.941        |
|    value_loss           | 0.34         |
------------------------------------------
Num timesteps: 360000
Best mean reward: -11.28 - Last mean reward per episode: -11.56
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 44           |
|    time_elapsed         | 10357        |
|    total_timesteps      | 360448       |
| train/                  |              |
|    approx_kl            | 0.0004293651 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.06        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.24         |
|    n_updates            | 473          |
|    policy_gradient_loss | -0.000439    |
|    std                  | 0.936        |
|    value_loss           | 0.393        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 45            |
|    time_elapsed         | 10595         |
|    total_timesteps      | 368640        |
| train/                  |               |
|    approx_kl            | 0.00023632983 |
|    clip_fraction        | 0.00945       |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.05         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.267         |
|    n_updates            | 484           |
|    policy_gradient_loss | 0.000114      |
|    std                  | 0.934         |
|    value_loss           | 0.395         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 46            |
|    time_elapsed         | 10835         |
|    total_timesteps      | 376832        |
| train/                  |               |
|    approx_kl            | 0.00061066914 |
|    clip_fraction        | 0.0304        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.05         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.304         |
|    n_updates            | 495           |
|    policy_gradient_loss | -0.000637     |
|    std                  | 0.935         |
|    value_loss           | 0.376         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 47           |
|    time_elapsed         | 11073        |
|    total_timesteps      | 385024       |
| train/                  |              |
|    approx_kl            | 0.0004505199 |
|    clip_fraction        | 0.0184       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.05        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.244        |
|    n_updates            | 506          |
|    policy_gradient_loss | -7.99e-05    |
|    std                  | 0.936        |
|    value_loss           | 0.336        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 48           |
|    time_elapsed         | 11313        |
|    total_timesteps      | 393216       |
| train/                  |              |
|    approx_kl            | 0.0007781838 |
|    clip_fraction        | 0.0465       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.04        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.361        |
|    n_updates            | 517          |
|    policy_gradient_loss | -0.00129     |
|    std                  | 0.931        |
|    value_loss           | 0.409        |
------------------------------------------
Num timesteps: 400000
Best mean reward: -11.28 - Last mean reward per episode: -11.05
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 49           |
|    time_elapsed         | 11551        |
|    total_timesteps      | 401408       |
| train/                  |              |
|    approx_kl            | 0.0002556299 |
|    clip_fraction        | 0.0142       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.03        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.237        |
|    n_updates            | 528          |
|    policy_gradient_loss | -2.66e-06    |
|    std                  | 0.929        |
|    value_loss           | 0.339        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 50           |
|    time_elapsed         | 11788        |
|    total_timesteps      | 409600       |
| train/                  |              |
|    approx_kl            | 0.0001854362 |
|    clip_fraction        | 0.0101       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.03        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.258        |
|    n_updates            | 539          |
|    policy_gradient_loss | 0.000163     |
|    std                  | 0.929        |
|    value_loss           | 0.318        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 51           |
|    time_elapsed         | 12023        |
|    total_timesteps      | 417792       |
| train/                  |              |
|    approx_kl            | 0.0005299635 |
|    clip_fraction        | 0.0217       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.03        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.279        |
|    n_updates            | 550          |
|    policy_gradient_loss | -0.000371    |
|    std                  | 0.928        |
|    value_loss           | 0.385        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 52            |
|    time_elapsed         | 12258         |
|    total_timesteps      | 425984        |
| train/                  |               |
|    approx_kl            | 0.00047840516 |
|    clip_fraction        | 0.016         |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.02         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.298         |
|    n_updates            | 561           |
|    policy_gradient_loss | -0.000248     |
|    std                  | 0.927         |
|    value_loss           | 0.397         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 53            |
|    time_elapsed         | 12498         |
|    total_timesteps      | 434176        |
| train/                  |               |
|    approx_kl            | 0.00044163226 |
|    clip_fraction        | 0.0192        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.02         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.279         |
|    n_updates            | 572           |
|    policy_gradient_loss | -0.00023      |
|    std                  | 0.925         |
|    value_loss           | 0.364         |
-------------------------------------------
Num timesteps: 440000
Best mean reward: -11.05 - Last mean reward per episode: -11.94
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 54            |
|    time_elapsed         | 12730         |
|    total_timesteps      | 442368        |
| train/                  |               |
|    approx_kl            | 0.00060338946 |
|    clip_fraction        | 0.0322        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.01         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.331         |
|    n_updates            | 583           |
|    policy_gradient_loss | -0.000659     |
|    std                  | 0.923         |
|    value_loss           | 0.392         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 55           |
|    time_elapsed         | 12963        |
|    total_timesteps      | 450560       |
| train/                  |              |
|    approx_kl            | 0.0005314621 |
|    clip_fraction        | 0.0229       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4           |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.265        |
|    n_updates            | 594          |
|    policy_gradient_loss | -0.000378    |
|    std                  | 0.92         |
|    value_loss           | 0.38         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 56           |
|    time_elapsed         | 13203        |
|    total_timesteps      | 458752       |
| train/                  |              |
|    approx_kl            | 0.0005204003 |
|    clip_fraction        | 0.0164       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.99        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.242        |
|    n_updates            | 605          |
|    policy_gradient_loss | -0.000116    |
|    std                  | 0.918        |
|    value_loss           | 0.313        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 57           |
|    time_elapsed         | 13440        |
|    total_timesteps      | 466944       |
| train/                  |              |
|    approx_kl            | 0.0005594835 |
|    clip_fraction        | 0.028        |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.99        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.284        |
|    n_updates            | 616          |
|    policy_gradient_loss | -0.000558    |
|    std                  | 0.915        |
|    value_loss           | 0.424        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 58           |
|    time_elapsed         | 13673        |
|    total_timesteps      | 475136       |
| train/                  |              |
|    approx_kl            | 0.0005722585 |
|    clip_fraction        | 0.0245       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.97        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.314        |
|    n_updates            | 627          |
|    policy_gradient_loss | -0.000743    |
|    std                  | 0.907        |
|    value_loss           | 0.418        |
------------------------------------------
Num timesteps: 480000
Best mean reward: -11.05 - Last mean reward per episode: -12.29
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 59            |
|    time_elapsed         | 13908         |
|    total_timesteps      | 483328        |
| train/                  |               |
|    approx_kl            | 0.00066248176 |
|    clip_fraction        | 0.0368        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.96         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.201         |
|    n_updates            | 638           |
|    policy_gradient_loss | -0.000685     |
|    std                  | 0.909         |
|    value_loss           | 0.328         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 60           |
|    time_elapsed         | 14146        |
|    total_timesteps      | 491520       |
| train/                  |              |
|    approx_kl            | 0.0005947208 |
|    clip_fraction        | 0.0261       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.96        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.286        |
|    n_updates            | 649          |
|    policy_gradient_loss | -0.000427    |
|    std                  | 0.906        |
|    value_loss           | 0.381        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 61            |
|    time_elapsed         | 14381         |
|    total_timesteps      | 499712        |
| train/                  |               |
|    approx_kl            | 0.00048343226 |
|    clip_fraction        | 0.0197        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.94         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.25          |
|    n_updates            | 660           |
|    policy_gradient_loss | -0.000333     |
|    std                  | 0.902         |
|    value_loss           | 0.361         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 62            |
|    time_elapsed         | 14618         |
|    total_timesteps      | 507904        |
| train/                  |               |
|    approx_kl            | 0.00067030033 |
|    clip_fraction        | 0.0385        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.94         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.317         |
|    n_updates            | 671           |
|    policy_gradient_loss | -0.000852     |
|    std                  | 0.901         |
|    value_loss           | 0.399         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 63            |
|    time_elapsed         | 14858         |
|    total_timesteps      | 516096        |
| train/                  |               |
|    approx_kl            | 0.00056445046 |
|    clip_fraction        | 0.0214        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.93         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.259         |
|    n_updates            | 682           |
|    policy_gradient_loss | -0.000298     |
|    std                  | 0.899         |
|    value_loss           | 0.356         |
-------------------------------------------
Num timesteps: 520000
Best mean reward: -11.05 - Last mean reward per episode: -11.00
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 64           |
|    time_elapsed         | 15100        |
|    total_timesteps      | 524288       |
| train/                  |              |
|    approx_kl            | 0.0006112034 |
|    clip_fraction        | 0.0283       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.92        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.285        |
|    n_updates            | 693          |
|    policy_gradient_loss | -0.000459    |
|    std                  | 0.897        |
|    value_loss           | 0.387        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 65           |
|    time_elapsed         | 15334        |
|    total_timesteps      | 532480       |
| train/                  |              |
|    approx_kl            | 0.0005385228 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.92        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.283        |
|    n_updates            | 704          |
|    policy_gradient_loss | -0.000443    |
|    std                  | 0.895        |
|    value_loss           | 0.325        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 66            |
|    time_elapsed         | 15569         |
|    total_timesteps      | 540672        |
| train/                  |               |
|    approx_kl            | 0.00033938466 |
|    clip_fraction        | 0.0216        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.91         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.23          |
|    n_updates            | 715           |
|    policy_gradient_loss | -0.000362     |
|    std                  | 0.893         |
|    value_loss           | 0.329         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 67           |
|    time_elapsed         | 15810        |
|    total_timesteps      | 548864       |
| train/                  |              |
|    approx_kl            | 0.0007592671 |
|    clip_fraction        | 0.0399       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.9         |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.342        |
|    n_updates            | 726          |
|    policy_gradient_loss | -0.00098     |
|    std                  | 0.891        |
|    value_loss           | 0.395        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 68           |
|    time_elapsed         | 16048        |
|    total_timesteps      | 557056       |
| train/                  |              |
|    approx_kl            | 0.0005319868 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.251        |
|    n_updates            | 737          |
|    policy_gradient_loss | -0.000299    |
|    std                  | 0.888        |
|    value_loss           | 0.354        |
------------------------------------------
Num timesteps: 560000
Best mean reward: -11.00 - Last mean reward per episode: -11.27
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 69           |
|    time_elapsed         | 16286        |
|    total_timesteps      | 565248       |
| train/                  |              |
|    approx_kl            | 0.0004729698 |
|    clip_fraction        | 0.0228       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.33         |
|    n_updates            | 748          |
|    policy_gradient_loss | -0.000329    |
|    std                  | 0.889        |
|    value_loss           | 0.398        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 70            |
|    time_elapsed         | 16523         |
|    total_timesteps      | 573440        |
| train/                  |               |
|    approx_kl            | 0.00057082763 |
|    clip_fraction        | 0.0152        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.89         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.249         |
|    n_updates            | 759           |
|    policy_gradient_loss | -0.000181     |
|    std                  | 0.888         |
|    value_loss           | 0.336         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 71            |
|    time_elapsed         | 16757         |
|    total_timesteps      | 581632        |
| train/                  |               |
|    approx_kl            | 0.00066462037 |
|    clip_fraction        | 0.025         |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.89         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.215         |
|    n_updates            | 770           |
|    policy_gradient_loss | -0.000578     |
|    std                  | 0.889         |
|    value_loss           | 0.369         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 72           |
|    time_elapsed         | 16997        |
|    total_timesteps      | 589824       |
| train/                  |              |
|    approx_kl            | 0.0003663838 |
|    clip_fraction        | 0.0197       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.89        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.259        |
|    n_updates            | 781          |
|    policy_gradient_loss | -0.000114    |
|    std                  | 0.887        |
|    value_loss           | 0.374        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 73           |
|    time_elapsed         | 17236        |
|    total_timesteps      | 598016       |
| train/                  |              |
|    approx_kl            | 0.0005169597 |
|    clip_fraction        | 0.0186       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.88        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.311        |
|    n_updates            | 792          |
|    policy_gradient_loss | -0.000186    |
|    std                  | 0.887        |
|    value_loss           | 0.377        |
------------------------------------------
Num timesteps: 600000
Best mean reward: -11.00 - Last mean reward per episode: -10.81
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 74           |
|    time_elapsed         | 17478        |
|    total_timesteps      | 606208       |
| train/                  |              |
|    approx_kl            | 0.0002560873 |
|    clip_fraction        | 0.0177       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.88        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.252        |
|    n_updates            | 803          |
|    policy_gradient_loss | -8.63e-05    |
|    std                  | 0.885        |
|    value_loss           | 0.363        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 75           |
|    time_elapsed         | 17713        |
|    total_timesteps      | 614400       |
| train/                  |              |
|    approx_kl            | 0.0005316411 |
|    clip_fraction        | 0.0204       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.88        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.299        |
|    n_updates            | 814          |
|    policy_gradient_loss | -0.000145    |
|    std                  | 0.885        |
|    value_loss           | 0.359        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 76            |
|    time_elapsed         | 17953         |
|    total_timesteps      | 622592        |
| train/                  |               |
|    approx_kl            | 0.00066324876 |
|    clip_fraction        | 0.0356        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.88         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.212         |
|    n_updates            | 825           |
|    policy_gradient_loss | -0.000767     |
|    std                  | 0.885         |
|    value_loss           | 0.281         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 77            |
|    time_elapsed         | 18192         |
|    total_timesteps      | 630784        |
| train/                  |               |
|    approx_kl            | 0.00051485916 |
|    clip_fraction        | 0.0199        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.86         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.27          |
|    n_updates            | 836           |
|    policy_gradient_loss | -0.0004       |
|    std                  | 0.88          |
|    value_loss           | 0.37          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 78            |
|    time_elapsed         | 18430         |
|    total_timesteps      | 638976        |
| train/                  |               |
|    approx_kl            | 0.00058567734 |
|    clip_fraction        | 0.0299        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.85         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.272         |
|    n_updates            | 847           |
|    policy_gradient_loss | -0.000624     |
|    std                  | 0.878         |
|    value_loss           | 0.379         |
-------------------------------------------
Num timesteps: 640000
Best mean reward: -10.81 - Last mean reward per episode: -11.68
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 79           |
|    time_elapsed         | 18668        |
|    total_timesteps      | 647168       |
| train/                  |              |
|    approx_kl            | 0.0004809696 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.85        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.22         |
|    n_updates            | 858          |
|    policy_gradient_loss | -0.000367    |
|    std                  | 0.876        |
|    value_loss           | 0.321        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 80           |
|    time_elapsed         | 18908        |
|    total_timesteps      | 655360       |
| train/                  |              |
|    approx_kl            | 0.0005926471 |
|    clip_fraction        | 0.021        |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.84        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.301        |
|    n_updates            | 869          |
|    policy_gradient_loss | -0.000471    |
|    std                  | 0.875        |
|    value_loss           | 0.36         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 81            |
|    time_elapsed         | 19143         |
|    total_timesteps      | 663552        |
| train/                  |               |
|    approx_kl            | 0.00025183562 |
|    clip_fraction        | 0.0179        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.84         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.318         |
|    n_updates            | 880           |
|    policy_gradient_loss | -0.00023      |
|    std                  | 0.875         |
|    value_loss           | 0.421         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 82           |
|    time_elapsed         | 19376        |
|    total_timesteps      | 671744       |
| train/                  |              |
|    approx_kl            | 0.0007430996 |
|    clip_fraction        | 0.0364       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.83        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.279        |
|    n_updates            | 891          |
|    policy_gradient_loss | -0.000797    |
|    std                  | 0.872        |
|    value_loss           | 0.357        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 83            |
|    time_elapsed         | 19614         |
|    total_timesteps      | 679936        |
| train/                  |               |
|    approx_kl            | 0.00025197119 |
|    clip_fraction        | 0.00819       |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.82         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.267         |
|    n_updates            | 902           |
|    policy_gradient_loss | -4.34e-05     |
|    std                  | 0.871         |
|    value_loss           | 0.373         |
-------------------------------------------
Num timesteps: 680000
Best mean reward: -10.81 - Last mean reward per episode: -11.38
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 84            |
|    time_elapsed         | 19854         |
|    total_timesteps      | 688128        |
| train/                  |               |
|    approx_kl            | 0.00064403226 |
|    clip_fraction        | 0.0514        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.82         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.254         |
|    n_updates            | 913           |
|    policy_gradient_loss | -0.00118      |
|    std                  | 0.869         |
|    value_loss           | 0.387         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 85            |
|    time_elapsed         | 20088         |
|    total_timesteps      | 696320        |
| train/                  |               |
|    approx_kl            | 0.00070318824 |
|    clip_fraction        | 0.0363        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.81         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.29          |
|    n_updates            | 924           |
|    policy_gradient_loss | -0.000623     |
|    std                  | 0.865         |
|    value_loss           | 0.418         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 86            |
|    time_elapsed         | 20327         |
|    total_timesteps      | 704512        |
| train/                  |               |
|    approx_kl            | 0.00049447187 |
|    clip_fraction        | 0.0255        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.8          |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.283         |
|    n_updates            | 935           |
|    policy_gradient_loss | -0.000275     |
|    std                  | 0.864         |
|    value_loss           | 0.388         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 87           |
|    time_elapsed         | 20564        |
|    total_timesteps      | 712704       |
| train/                  |              |
|    approx_kl            | 0.0004808997 |
|    clip_fraction        | 0.0251       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.8         |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.272        |
|    n_updates            | 946          |
|    policy_gradient_loss | -0.000301    |
|    std                  | 0.864        |
|    value_loss           | 0.338        |
------------------------------------------
Num timesteps: 720000
Best mean reward: -10.81 - Last mean reward per episode: -10.86
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 88            |
|    time_elapsed         | 20798         |
|    total_timesteps      | 720896        |
| train/                  |               |
|    approx_kl            | 0.00063199055 |
|    clip_fraction        | 0.0255        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.8          |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.254         |
|    n_updates            | 957           |
|    policy_gradient_loss | -0.000434     |
|    std                  | 0.863         |
|    value_loss           | 0.326         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 89            |
|    time_elapsed         | 21038         |
|    total_timesteps      | 729088        |
| train/                  |               |
|    approx_kl            | 0.00034531963 |
|    clip_fraction        | 0.0221        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.8          |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.227         |
|    n_updates            | 968           |
|    policy_gradient_loss | -0.000312     |
|    std                  | 0.863         |
|    value_loss           | 0.341         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 90            |
|    time_elapsed         | 21275         |
|    total_timesteps      | 737280        |
| train/                  |               |
|    approx_kl            | 0.00039724732 |
|    clip_fraction        | 0.0187        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.79         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.271         |
|    n_updates            | 979           |
|    policy_gradient_loss | -0.000284     |
|    std                  | 0.859         |
|    value_loss           | 0.366         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 91            |
|    time_elapsed         | 21512         |
|    total_timesteps      | 745472        |
| train/                  |               |
|    approx_kl            | 0.00061452115 |
|    clip_fraction        | 0.0266        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.77         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.283         |
|    n_updates            | 990           |
|    policy_gradient_loss | -0.000387     |
|    std                  | 0.856         |
|    value_loss           | 0.385         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 92            |
|    time_elapsed         | 21748         |
|    total_timesteps      | 753664        |
| train/                  |               |
|    approx_kl            | 0.00075921515 |
|    clip_fraction        | 0.0386        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.77         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.282         |
|    n_updates            | 1001          |
|    policy_gradient_loss | -0.000825     |
|    std                  | 0.857         |
|    value_loss           | 0.387         |
-------------------------------------------
Num timesteps: 760000
Best mean reward: -10.81 - Last mean reward per episode: -11.15
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 93           |
|    time_elapsed         | 21980        |
|    total_timesteps      | 761856       |
| train/                  |              |
|    approx_kl            | 0.0006200711 |
|    clip_fraction        | 0.023        |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.77        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.297        |
|    n_updates            | 1012         |
|    policy_gradient_loss | -0.000498    |
|    std                  | 0.855        |
|    value_loss           | 0.401        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 94            |
|    time_elapsed         | 22217         |
|    total_timesteps      | 770048        |
| train/                  |               |
|    approx_kl            | 0.00069925474 |
|    clip_fraction        | 0.0359        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.76         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.272         |
|    n_updates            | 1023          |
|    policy_gradient_loss | -0.000483     |
|    std                  | 0.854         |
|    value_loss           | 0.386         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 95           |
|    time_elapsed         | 22455        |
|    total_timesteps      | 778240       |
| train/                  |              |
|    approx_kl            | 0.0004476958 |
|    clip_fraction        | 0.0225       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.76        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.255        |
|    n_updates            | 1034         |
|    policy_gradient_loss | -0.000257    |
|    std                  | 0.851        |
|    value_loss           | 0.304        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 96           |
|    time_elapsed         | 22697        |
|    total_timesteps      | 786432       |
| train/                  |              |
|    approx_kl            | 0.0005936383 |
|    clip_fraction        | 0.0254       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.75        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.256        |
|    n_updates            | 1045         |
|    policy_gradient_loss | -0.000606    |
|    std                  | 0.849        |
|    value_loss           | 0.359        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 97           |
|    time_elapsed         | 22933        |
|    total_timesteps      | 794624       |
| train/                  |              |
|    approx_kl            | 0.0003181062 |
|    clip_fraction        | 0.00678      |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.75        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.295        |
|    n_updates            | 1056         |
|    policy_gradient_loss | 4.96e-05     |
|    std                  | 0.851        |
|    value_loss           | 0.356        |
------------------------------------------
Num timesteps: 800000
Best mean reward: -10.81 - Last mean reward per episode: -11.88
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 98           |
|    time_elapsed         | 23172        |
|    total_timesteps      | 802816       |
| train/                  |              |
|    approx_kl            | 0.0007174956 |
|    clip_fraction        | 0.0563       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.75        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.355        |
|    n_updates            | 1067         |
|    policy_gradient_loss | -0.00153     |
|    std                  | 0.848        |
|    value_loss           | 0.418        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 99            |
|    time_elapsed         | 23412         |
|    total_timesteps      | 811008        |
| train/                  |               |
|    approx_kl            | 0.00044166134 |
|    clip_fraction        | 0.0229        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.74         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.277         |
|    n_updates            | 1078          |
|    policy_gradient_loss | -0.000423     |
|    std                  | 0.846         |
|    value_loss           | 0.358         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 100           |
|    time_elapsed         | 23651         |
|    total_timesteps      | 819200        |
| train/                  |               |
|    approx_kl            | 0.00055784173 |
|    clip_fraction        | 0.033         |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.73         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.267         |
|    n_updates            | 1089          |
|    policy_gradient_loss | -0.000774     |
|    std                  | 0.843         |
|    value_loss           | 0.341         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 101           |
|    time_elapsed         | 23886         |
|    total_timesteps      | 827392        |
| train/                  |               |
|    approx_kl            | 0.00044059404 |
|    clip_fraction        | 0.0195        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.72         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.233         |
|    n_updates            | 1100          |
|    policy_gradient_loss | -0.000327     |
|    std                  | 0.84          |
|    value_loss           | 0.323         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 102           |
|    time_elapsed         | 24120         |
|    total_timesteps      | 835584        |
| train/                  |               |
|    approx_kl            | 0.00045717548 |
|    clip_fraction        | 0.021         |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.71         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.239         |
|    n_updates            | 1111          |
|    policy_gradient_loss | -6.39e-05     |
|    std                  | 0.836         |
|    value_loss           | 0.393         |
-------------------------------------------
Num timesteps: 840000
Best mean reward: -10.81 - Last mean reward per episode: -11.17
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 103           |
|    time_elapsed         | 24360         |
|    total_timesteps      | 843776        |
| train/                  |               |
|    approx_kl            | 0.00052685535 |
|    clip_fraction        | 0.0272        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.69         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.297         |
|    n_updates            | 1122          |
|    policy_gradient_loss | -0.000832     |
|    std                  | 0.83          |
|    value_loss           | 0.384         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 104           |
|    time_elapsed         | 24599         |
|    total_timesteps      | 851968        |
| train/                  |               |
|    approx_kl            | 0.00046515028 |
|    clip_fraction        | 0.0162        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.68         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.246         |
|    n_updates            | 1133          |
|    policy_gradient_loss | -0.000295     |
|    std                  | 0.83          |
|    value_loss           | 0.363         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 105          |
|    time_elapsed         | 24837        |
|    total_timesteps      | 860160       |
| train/                  |              |
|    approx_kl            | 0.0006810642 |
|    clip_fraction        | 0.0499       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.68        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.283        |
|    n_updates            | 1144         |
|    policy_gradient_loss | -0.00131     |
|    std                  | 0.829        |
|    value_loss           | 0.367        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 106           |
|    time_elapsed         | 25077         |
|    total_timesteps      | 868352        |
| train/                  |               |
|    approx_kl            | 0.00068888825 |
|    clip_fraction        | 0.0379        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.67         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.29          |
|    n_updates            | 1155          |
|    policy_gradient_loss | -0.000403     |
|    std                  | 0.828         |
|    value_loss           | 0.37          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 107           |
|    time_elapsed         | 25317         |
|    total_timesteps      | 876544        |
| train/                  |               |
|    approx_kl            | 0.00039831534 |
|    clip_fraction        | 0.0178        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.67         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.229         |
|    n_updates            | 1166          |
|    policy_gradient_loss | -0.000276     |
|    std                  | 0.829         |
|    value_loss           | 0.358         |
-------------------------------------------
Num timesteps: 880000
Best mean reward: -10.81 - Last mean reward per episode: -11.85
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 108           |
|    time_elapsed         | 25556         |
|    total_timesteps      | 884736        |
| train/                  |               |
|    approx_kl            | 0.00050814985 |
|    clip_fraction        | 0.0153        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.66         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.277         |
|    n_updates            | 1177          |
|    policy_gradient_loss | -0.000393     |
|    std                  | 0.825         |
|    value_loss           | 0.4           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -11.1       |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 109         |
|    time_elapsed         | 25799       |
|    total_timesteps      | 892928      |
| train/                  |             |
|    approx_kl            | 0.000672865 |
|    clip_fraction        | 0.0283      |
|    clip_range           | 0.075       |
|    entropy_loss         | -3.65       |
|    explained_variance   | 0           |
|    learning_rate        | 0.000168    |
|    loss                 | 0.275       |
|    n_updates            | 1188        |
|    policy_gradient_loss | -0.000709   |
|    std                  | 0.822       |
|    value_loss           | 0.352       |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 110           |
|    time_elapsed         | 26039         |
|    total_timesteps      | 901120        |
| train/                  |               |
|    approx_kl            | 0.00052557373 |
|    clip_fraction        | 0.0273        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.64         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.223         |
|    n_updates            | 1199          |
|    policy_gradient_loss | -0.000574     |
|    std                  | 0.82          |
|    value_loss           | 0.306         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 111           |
|    time_elapsed         | 26279         |
|    total_timesteps      | 909312        |
| train/                  |               |
|    approx_kl            | 0.00051579234 |
|    clip_fraction        | 0.0132        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.63         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.243         |
|    n_updates            | 1210          |
|    policy_gradient_loss | -8.59e-05     |
|    std                  | 0.819         |
|    value_loss           | 0.329         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 112          |
|    time_elapsed         | 26514        |
|    total_timesteps      | 917504       |
| train/                  |              |
|    approx_kl            | 0.0005917869 |
|    clip_fraction        | 0.0305       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.63        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.229        |
|    n_updates            | 1221         |
|    policy_gradient_loss | -0.000308    |
|    std                  | 0.819        |
|    value_loss           | 0.322        |
------------------------------------------
Num timesteps: 920000
Best mean reward: -10.81 - Last mean reward per episode: -10.72
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 113          |
|    time_elapsed         | 26756        |
|    total_timesteps      | 925696       |
| train/                  |              |
|    approx_kl            | 0.0004610523 |
|    clip_fraction        | 0.0237       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.62        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.246        |
|    n_updates            | 1232         |
|    policy_gradient_loss | -0.000275    |
|    std                  | 0.816        |
|    value_loss           | 0.322        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 114          |
|    time_elapsed         | 26990        |
|    total_timesteps      | 933888       |
| train/                  |              |
|    approx_kl            | 0.0002156978 |
|    clip_fraction        | 0.0144       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.61        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.249        |
|    n_updates            | 1243         |
|    policy_gradient_loss | -0.000243    |
|    std                  | 0.813        |
|    value_loss           | 0.36         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 115          |
|    time_elapsed         | 27225        |
|    total_timesteps      | 942080       |
| train/                  |              |
|    approx_kl            | 0.0003929669 |
|    clip_fraction        | 0.0185       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.59        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.198        |
|    n_updates            | 1254         |
|    policy_gradient_loss | -0.000447    |
|    std                  | 0.808        |
|    value_loss           | 0.275        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 116           |
|    time_elapsed         | 27461         |
|    total_timesteps      | 950272        |
| train/                  |               |
|    approx_kl            | 0.00059066806 |
|    clip_fraction        | 0.0243        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.58         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.234         |
|    n_updates            | 1265          |
|    policy_gradient_loss | -0.000572     |
|    std                  | 0.806         |
|    value_loss           | 0.32          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 117          |
|    time_elapsed         | 27696        |
|    total_timesteps      | 958464       |
| train/                  |              |
|    approx_kl            | 0.0006537776 |
|    clip_fraction        | 0.0306       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.57        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.322        |
|    n_updates            | 1276         |
|    policy_gradient_loss | -0.000476    |
|    std                  | 0.802        |
|    value_loss           | 0.345        |
------------------------------------------
Num timesteps: 960000
Best mean reward: -10.72 - Last mean reward per episode: -10.68
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 118          |
|    time_elapsed         | 27930        |
|    total_timesteps      | 966656       |
| train/                  |              |
|    approx_kl            | 0.0007887058 |
|    clip_fraction        | 0.0519       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.56        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.231        |
|    n_updates            | 1287         |
|    policy_gradient_loss | -0.00143     |
|    std                  | 0.8          |
|    value_loss           | 0.356        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 119          |
|    time_elapsed         | 28166        |
|    total_timesteps      | 974848       |
| train/                  |              |
|    approx_kl            | 0.0003758283 |
|    clip_fraction        | 0.0128       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.55        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.221        |
|    n_updates            | 1298         |
|    policy_gradient_loss | -0.000129    |
|    std                  | 0.796        |
|    value_loss           | 0.322        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 120           |
|    time_elapsed         | 28404         |
|    total_timesteps      | 983040        |
| train/                  |               |
|    approx_kl            | 0.00067139126 |
|    clip_fraction        | 0.0284        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.53         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.229         |
|    n_updates            | 1309          |
|    policy_gradient_loss | -0.000542     |
|    std                  | 0.791         |
|    value_loss           | 0.305         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 121           |
|    time_elapsed         | 28635         |
|    total_timesteps      | 991232        |
| train/                  |               |
|    approx_kl            | 0.00051410875 |
|    clip_fraction        | 0.0272        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.52         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.25          |
|    n_updates            | 1320          |
|    policy_gradient_loss | -0.000367     |
|    std                  | 0.789         |
|    value_loss           | 0.366         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 122           |
|    time_elapsed         | 28874         |
|    total_timesteps      | 999424        |
| train/                  |               |
|    approx_kl            | 0.00044030184 |
|    clip_fraction        | 0.0145        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.52         |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.25          |
|    n_updates            | 1331          |
|    policy_gradient_loss | -0.000227     |
|    std                  | 0.79          |
|    value_loss           | 0.369         |
-------------------------------------------
Num timesteps: 1000000
Best mean reward: -10.68 - Last mean reward per episode: -10.96
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 123           |
|    time_elapsed         | 29114         |
|    total_timesteps      | 1007616       |
| train/                  |               |
|    approx_kl            | 0.00023103735 |
|    clip_fraction        | 0.0118        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.52         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.226         |
|    n_updates            | 1342          |
|    policy_gradient_loss | 2.5e-05       |
|    std                  | 0.789         |
|    value_loss           | 0.362         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 124           |
|    time_elapsed         | 29354         |
|    total_timesteps      | 1015808       |
| train/                  |               |
|    approx_kl            | 0.00042924308 |
|    clip_fraction        | 0.0134        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.52         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.279         |
|    n_updates            | 1353          |
|    policy_gradient_loss | -0.000285     |
|    std                  | 0.79          |
|    value_loss           | 0.349         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 125           |
|    time_elapsed         | 29589         |
|    total_timesteps      | 1024000       |
| train/                  |               |
|    approx_kl            | 0.00047226774 |
|    clip_fraction        | 0.0183        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.52         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.221         |
|    n_updates            | 1364          |
|    policy_gradient_loss | -0.000124     |
|    std                  | 0.789         |
|    value_loss           | 0.329         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 126          |
|    time_elapsed         | 29826        |
|    total_timesteps      | 1032192      |
| train/                  |              |
|    approx_kl            | 0.0006718135 |
|    clip_fraction        | 0.0394       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.52        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.283        |
|    n_updates            | 1375         |
|    policy_gradient_loss | -0.000681    |
|    std                  | 0.789        |
|    value_loss           | 0.358        |
------------------------------------------
Num timesteps: 1040000
Best mean reward: -10.68 - Last mean reward per episode: -10.80
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 127          |
|    time_elapsed         | 30064        |
|    total_timesteps      | 1040384      |
| train/                  |              |
|    approx_kl            | 0.0005567665 |
|    clip_fraction        | 0.0206       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.51        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.25         |
|    n_updates            | 1386         |
|    policy_gradient_loss | -0.000258    |
|    std                  | 0.788        |
|    value_loss           | 0.362        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 128          |
|    time_elapsed         | 30301        |
|    total_timesteps      | 1048576      |
| train/                  |              |
|    approx_kl            | 0.0006648279 |
|    clip_fraction        | 0.025        |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.51        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.277        |
|    n_updates            | 1397         |
|    policy_gradient_loss | -0.000597    |
|    std                  | 0.786        |
|    value_loss           | 0.34         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 129          |
|    time_elapsed         | 30533        |
|    total_timesteps      | 1056768      |
| train/                  |              |
|    approx_kl            | 0.0005556798 |
|    clip_fraction        | 0.03         |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.51        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.272        |
|    n_updates            | 1408         |
|    policy_gradient_loss | -0.000428    |
|    std                  | 0.787        |
|    value_loss           | 0.355        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 130           |
|    time_elapsed         | 30768         |
|    total_timesteps      | 1064960       |
| train/                  |               |
|    approx_kl            | 0.00066931074 |
|    clip_fraction        | 0.0255        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.5          |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.235         |
|    n_updates            | 1419          |
|    policy_gradient_loss | -0.00027      |
|    std                  | 0.783         |
|    value_loss           | 0.327         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 131           |
|    time_elapsed         | 31002         |
|    total_timesteps      | 1073152       |
| train/                  |               |
|    approx_kl            | 0.00027147142 |
|    clip_fraction        | 0.00983       |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.48         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.258         |
|    n_updates            | 1430          |
|    policy_gradient_loss | 0.000142      |
|    std                  | 0.78          |
|    value_loss           | 0.296         |
-------------------------------------------
Num timesteps: 1080000
Best mean reward: -10.68 - Last mean reward per episode: -10.89
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 132          |
|    time_elapsed         | 31238        |
|    total_timesteps      | 1081344      |
| train/                  |              |
|    approx_kl            | 0.0003678556 |
|    clip_fraction        | 0.0211       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.48        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.301        |
|    n_updates            | 1441         |
|    policy_gradient_loss | -0.00036     |
|    std                  | 0.779        |
|    value_loss           | 0.376        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 133          |
|    time_elapsed         | 31472        |
|    total_timesteps      | 1089536      |
| train/                  |              |
|    approx_kl            | 0.0005473771 |
|    clip_fraction        | 0.0166       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.48        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.259        |
|    n_updates            | 1452         |
|    policy_gradient_loss | -0.000187    |
|    std                  | 0.78         |
|    value_loss           | 0.355        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 134          |
|    time_elapsed         | 31710        |
|    total_timesteps      | 1097728      |
| train/                  |              |
|    approx_kl            | 0.0006554965 |
|    clip_fraction        | 0.0392       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.47        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.218        |
|    n_updates            | 1463         |
|    policy_gradient_loss | -0.000697    |
|    std                  | 0.777        |
|    value_loss           | 0.301        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 135          |
|    time_elapsed         | 31948        |
|    total_timesteps      | 1105920      |
| train/                  |              |
|    approx_kl            | 0.0005858183 |
|    clip_fraction        | 0.0219       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.46        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.309        |
|    n_updates            | 1474         |
|    policy_gradient_loss | -0.000472    |
|    std                  | 0.773        |
|    value_loss           | 0.363        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 136           |
|    time_elapsed         | 32190         |
|    total_timesteps      | 1114112       |
| train/                  |               |
|    approx_kl            | 0.00050398987 |
|    clip_fraction        | 0.02          |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.45         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.252         |
|    n_updates            | 1485          |
|    policy_gradient_loss | -0.00022      |
|    std                  | 0.771         |
|    value_loss           | 0.306         |
-------------------------------------------
Num timesteps: 1120000
Best mean reward: -10.68 - Last mean reward per episode: -10.60
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 137          |
|    time_elapsed         | 32431        |
|    total_timesteps      | 1122304      |
| train/                  |              |
|    approx_kl            | 0.0003893614 |
|    clip_fraction        | 0.0154       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.44        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.207        |
|    n_updates            | 1496         |
|    policy_gradient_loss | -0.000164    |
|    std                  | 0.77         |
|    value_loss           | 0.3          |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 138           |
|    time_elapsed         | 32674         |
|    total_timesteps      | 1130496       |
| train/                  |               |
|    approx_kl            | 0.00043640297 |
|    clip_fraction        | 0.0195        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.42         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.17          |
|    n_updates            | 1507          |
|    policy_gradient_loss | -0.000419     |
|    std                  | 0.763         |
|    value_loss           | 0.264         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 139           |
|    time_elapsed         | 32916         |
|    total_timesteps      | 1138688       |
| train/                  |               |
|    approx_kl            | 0.00024177757 |
|    clip_fraction        | 0.025         |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.41         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.227         |
|    n_updates            | 1518          |
|    policy_gradient_loss | -0.000439     |
|    std                  | 0.762         |
|    value_loss           | 0.305         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 140           |
|    time_elapsed         | 33151         |
|    total_timesteps      | 1146880       |
| train/                  |               |
|    approx_kl            | 0.00020887009 |
|    clip_fraction        | 0.00617       |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.4          |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.268         |
|    n_updates            | 1529          |
|    policy_gradient_loss | -5.77e-06     |
|    std                  | 0.759         |
|    value_loss           | 0.31          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 141           |
|    time_elapsed         | 33387         |
|    total_timesteps      | 1155072       |
| train/                  |               |
|    approx_kl            | 0.00040640967 |
|    clip_fraction        | 0.0231        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.39         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.243         |
|    n_updates            | 1540          |
|    policy_gradient_loss | -0.00047      |
|    std                  | 0.759         |
|    value_loss           | 0.321         |
-------------------------------------------
Num timesteps: 1160000
Best mean reward: -10.60 - Last mean reward per episode: -11.13
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.1        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 142          |
|    time_elapsed         | 33624        |
|    total_timesteps      | 1163264      |
| train/                  |              |
|    approx_kl            | 0.0005029716 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.39        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.222        |
|    n_updates            | 1551         |
|    policy_gradient_loss | -0.000524    |
|    std                  | 0.756        |
|    value_loss           | 0.314        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 143          |
|    time_elapsed         | 33861        |
|    total_timesteps      | 1171456      |
| train/                  |              |
|    approx_kl            | 0.0006095988 |
|    clip_fraction        | 0.0197       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.38        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.275        |
|    n_updates            | 1562         |
|    policy_gradient_loss | -0.000235    |
|    std                  | 0.754        |
|    value_loss           | 0.315        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 144           |
|    time_elapsed         | 34096         |
|    total_timesteps      | 1179648       |
| train/                  |               |
|    approx_kl            | 0.00032924424 |
|    clip_fraction        | 0.0185        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.37         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.207         |
|    n_updates            | 1573          |
|    policy_gradient_loss | -0.000135     |
|    std                  | 0.753         |
|    value_loss           | 0.318         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 145          |
|    time_elapsed         | 34332        |
|    total_timesteps      | 1187840      |
| train/                  |              |
|    approx_kl            | 0.0005262936 |
|    clip_fraction        | 0.0259       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.36        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.213        |
|    n_updates            | 1584         |
|    policy_gradient_loss | -0.000661    |
|    std                  | 0.749        |
|    value_loss           | 0.33         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 146          |
|    time_elapsed         | 34569        |
|    total_timesteps      | 1196032      |
| train/                  |              |
|    approx_kl            | 0.0005244949 |
|    clip_fraction        | 0.0249       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.34        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.244        |
|    n_updates            | 1595         |
|    policy_gradient_loss | -0.000463    |
|    std                  | 0.745        |
|    value_loss           | 0.371        |
------------------------------------------
Num timesteps: 1200000
Best mean reward: -10.60 - Last mean reward per episode: -11.61
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 147           |
|    time_elapsed         | 34807         |
|    total_timesteps      | 1204224       |
| train/                  |               |
|    approx_kl            | 0.00061660307 |
|    clip_fraction        | 0.0284        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.34         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.194         |
|    n_updates            | 1606          |
|    policy_gradient_loss | -0.000367     |
|    std                  | 0.745         |
|    value_loss           | 0.321         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 148          |
|    time_elapsed         | 35046        |
|    total_timesteps      | 1212416      |
| train/                  |              |
|    approx_kl            | 0.0005583246 |
|    clip_fraction        | 0.0169       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.33        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.289        |
|    n_updates            | 1617         |
|    policy_gradient_loss | -0.000171    |
|    std                  | 0.743        |
|    value_loss           | 0.358        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 149           |
|    time_elapsed         | 35282         |
|    total_timesteps      | 1220608       |
| train/                  |               |
|    approx_kl            | 0.00045500233 |
|    clip_fraction        | 0.0144        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.33         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.266         |
|    n_updates            | 1628          |
|    policy_gradient_loss | 2.95e-05      |
|    std                  | 0.743         |
|    value_loss           | 0.341         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 150           |
|    time_elapsed         | 35518         |
|    total_timesteps      | 1228800       |
| train/                  |               |
|    approx_kl            | 0.00073573564 |
|    clip_fraction        | 0.0397        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.32         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.267         |
|    n_updates            | 1639          |
|    policy_gradient_loss | -0.000876     |
|    std                  | 0.741         |
|    value_loss           | 0.307         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 151          |
|    time_elapsed         | 35753        |
|    total_timesteps      | 1236992      |
| train/                  |              |
|    approx_kl            | 0.0003594519 |
|    clip_fraction        | 0.0119       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.31        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.203        |
|    n_updates            | 1650         |
|    policy_gradient_loss | -0.000126    |
|    std                  | 0.739        |
|    value_loss           | 0.294        |
------------------------------------------
Num timesteps: 1240000
Best mean reward: -10.60 - Last mean reward per episode: -10.88
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 152           |
|    time_elapsed         | 35989         |
|    total_timesteps      | 1245184       |
| train/                  |               |
|    approx_kl            | 0.00056356564 |
|    clip_fraction        | 0.0208        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.31         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.237         |
|    n_updates            | 1661          |
|    policy_gradient_loss | -8.49e-05     |
|    std                  | 0.737         |
|    value_loss           | 0.34          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 153           |
|    time_elapsed         | 36228         |
|    total_timesteps      | 1253376       |
| train/                  |               |
|    approx_kl            | 0.00055845524 |
|    clip_fraction        | 0.0268        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.3          |
|    explained_variance   | 5.96e-08      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.252         |
|    n_updates            | 1672          |
|    policy_gradient_loss | -0.000529     |
|    std                  | 0.736         |
|    value_loss           | 0.35          |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 154           |
|    time_elapsed         | 36465         |
|    total_timesteps      | 1261568       |
| train/                  |               |
|    approx_kl            | 0.00038150695 |
|    clip_fraction        | 0.0213        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.29         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.232         |
|    n_updates            | 1683          |
|    policy_gradient_loss | -0.000101     |
|    std                  | 0.734         |
|    value_loss           | 0.282         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 155          |
|    time_elapsed         | 36704        |
|    total_timesteps      | 1269760      |
| train/                  |              |
|    approx_kl            | 0.0007216943 |
|    clip_fraction        | 0.0437       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.29        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.278        |
|    n_updates            | 1694         |
|    policy_gradient_loss | -0.000972    |
|    std                  | 0.734        |
|    value_loss           | 0.35         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.1         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 156           |
|    time_elapsed         | 36943         |
|    total_timesteps      | 1277952       |
| train/                  |               |
|    approx_kl            | 0.00044263108 |
|    clip_fraction        | 0.0153        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.28         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.212         |
|    n_updates            | 1705          |
|    policy_gradient_loss | -0.000182     |
|    std                  | 0.73          |
|    value_loss           | 0.302         |
-------------------------------------------
Num timesteps: 1280000
Best mean reward: -10.60 - Last mean reward per episode: -11.36
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 157           |
|    time_elapsed         | 37179         |
|    total_timesteps      | 1286144       |
| train/                  |               |
|    approx_kl            | 0.00046003825 |
|    clip_fraction        | 0.0186        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.27         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.191         |
|    n_updates            | 1716          |
|    policy_gradient_loss | -0.000154     |
|    std                  | 0.728         |
|    value_loss           | 0.297         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 158           |
|    time_elapsed         | 37416         |
|    total_timesteps      | 1294336       |
| train/                  |               |
|    approx_kl            | 0.00039908505 |
|    clip_fraction        | 0.0104        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.25         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.212         |
|    n_updates            | 1727          |
|    policy_gradient_loss | -7.93e-05     |
|    std                  | 0.724         |
|    value_loss           | 0.3           |
-------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -10.8       |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 159         |
|    time_elapsed         | 37655       |
|    total_timesteps      | 1302528     |
| train/                  |             |
|    approx_kl            | 0.000209823 |
|    clip_fraction        | 0.01        |
|    clip_range           | 0.075       |
|    entropy_loss         | -3.25       |
|    explained_variance   | 5.96e-08    |
|    learning_rate        | 0.000168    |
|    loss                 | 0.27        |
|    n_updates            | 1738        |
|    policy_gradient_loss | -0.000112   |
|    std                  | 0.725       |
|    value_loss           | 0.344       |
-----------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 160           |
|    time_elapsed         | 37895         |
|    total_timesteps      | 1310720       |
| train/                  |               |
|    approx_kl            | 0.00056405744 |
|    clip_fraction        | 0.0173        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.24         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.314         |
|    n_updates            | 1749          |
|    policy_gradient_loss | -0.000128     |
|    std                  | 0.724         |
|    value_loss           | 0.357         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 161          |
|    time_elapsed         | 38134        |
|    total_timesteps      | 1318912      |
| train/                  |              |
|    approx_kl            | 0.0006376257 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.24        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.224        |
|    n_updates            | 1760         |
|    policy_gradient_loss | -0.00102     |
|    std                  | 0.723        |
|    value_loss           | 0.301        |
------------------------------------------
Num timesteps: 1320000
Best mean reward: -10.60 - Last mean reward per episode: -10.94
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 162           |
|    time_elapsed         | 38373         |
|    total_timesteps      | 1327104       |
| train/                  |               |
|    approx_kl            | 0.00027512957 |
|    clip_fraction        | 0.0083        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.23         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.279         |
|    n_updates            | 1771          |
|    policy_gradient_loss | -0.000145     |
|    std                  | 0.72          |
|    value_loss           | 0.347         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 163           |
|    time_elapsed         | 38609         |
|    total_timesteps      | 1335296       |
| train/                  |               |
|    approx_kl            | 0.00031206815 |
|    clip_fraction        | 0.0152        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.22         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.229         |
|    n_updates            | 1782          |
|    policy_gradient_loss | 1.7e-05       |
|    std                  | 0.719         |
|    value_loss           | 0.286         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.3         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 164           |
|    time_elapsed         | 38848         |
|    total_timesteps      | 1343488       |
| train/                  |               |
|    approx_kl            | 0.00038204575 |
|    clip_fraction        | 0.0143        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.21         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.228         |
|    n_updates            | 1793          |
|    policy_gradient_loss | -6.86e-05     |
|    std                  | 0.715         |
|    value_loss           | 0.308         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 165           |
|    time_elapsed         | 39083         |
|    total_timesteps      | 1351680       |
| train/                  |               |
|    approx_kl            | 0.00046133244 |
|    clip_fraction        | 0.0222        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.21         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.215         |
|    n_updates            | 1804          |
|    policy_gradient_loss | -0.000357     |
|    std                  | 0.717         |
|    value_loss           | 0.278         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 166           |
|    time_elapsed         | 39316         |
|    total_timesteps      | 1359872       |
| train/                  |               |
|    approx_kl            | 0.00057665777 |
|    clip_fraction        | 0.0297        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.2          |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.224         |
|    n_updates            | 1815          |
|    policy_gradient_loss | -0.000532     |
|    std                  | 0.714         |
|    value_loss           | 0.318         |
-------------------------------------------
Num timesteps: 1360000
Best mean reward: -10.60 - Last mean reward per episode: -10.39
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 167           |
|    time_elapsed         | 39552         |
|    total_timesteps      | 1368064       |
| train/                  |               |
|    approx_kl            | 0.00044508482 |
|    clip_fraction        | 0.0189        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.2          |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.27          |
|    n_updates            | 1826          |
|    policy_gradient_loss | -0.000172     |
|    std                  | 0.713         |
|    value_loss           | 0.347         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 168           |
|    time_elapsed         | 39788         |
|    total_timesteps      | 1376256       |
| train/                  |               |
|    approx_kl            | 0.00047355331 |
|    clip_fraction        | 0.0141        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.19         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.245         |
|    n_updates            | 1837          |
|    policy_gradient_loss | -8.71e-05     |
|    std                  | 0.711         |
|    value_loss           | 0.303         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 169           |
|    time_elapsed         | 40023         |
|    total_timesteps      | 1384448       |
| train/                  |               |
|    approx_kl            | 0.00024240292 |
|    clip_fraction        | 0.0114        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.18         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.247         |
|    n_updates            | 1848          |
|    policy_gradient_loss | -8.32e-05     |
|    std                  | 0.706         |
|    value_loss           | 0.331         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 170           |
|    time_elapsed         | 40261         |
|    total_timesteps      | 1392640       |
| train/                  |               |
|    approx_kl            | 0.00058642717 |
|    clip_fraction        | 0.0233        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.16         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.214         |
|    n_updates            | 1859          |
|    policy_gradient_loss | -0.000666     |
|    std                  | 0.702         |
|    value_loss           | 0.306         |
-------------------------------------------
Num timesteps: 1400000
Best mean reward: -10.39 - Last mean reward per episode: -10.57
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 171           |
|    time_elapsed         | 40501         |
|    total_timesteps      | 1400832       |
| train/                  |               |
|    approx_kl            | 0.00036734744 |
|    clip_fraction        | 0.0192        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.15         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.224         |
|    n_updates            | 1870          |
|    policy_gradient_loss | -0.000254     |
|    std                  | 0.703         |
|    value_loss           | 0.3           |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 172          |
|    time_elapsed         | 40741        |
|    total_timesteps      | 1409024      |
| train/                  |              |
|    approx_kl            | 0.0006765468 |
|    clip_fraction        | 0.037        |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.14        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.245        |
|    n_updates            | 1881         |
|    policy_gradient_loss | -0.000598    |
|    std                  | 0.701        |
|    value_loss           | 0.31         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 173           |
|    time_elapsed         | 40976         |
|    total_timesteps      | 1417216       |
| train/                  |               |
|    approx_kl            | 0.00068033236 |
|    clip_fraction        | 0.0336        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.14         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.247         |
|    n_updates            | 1892          |
|    policy_gradient_loss | -0.000816     |
|    std                  | 0.699         |
|    value_loss           | 0.322         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 174          |
|    time_elapsed         | 41216        |
|    total_timesteps      | 1425408      |
| train/                  |              |
|    approx_kl            | 0.0005249537 |
|    clip_fraction        | 0.0271       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.13        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.246        |
|    n_updates            | 1903         |
|    policy_gradient_loss | -0.000564    |
|    std                  | 0.697        |
|    value_loss           | 0.323        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 175          |
|    time_elapsed         | 41456        |
|    total_timesteps      | 1433600      |
| train/                  |              |
|    approx_kl            | 0.0005861147 |
|    clip_fraction        | 0.0375       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.12        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.252        |
|    n_updates            | 1914         |
|    policy_gradient_loss | -0.000789    |
|    std                  | 0.695        |
|    value_loss           | 0.303        |
------------------------------------------
Num timesteps: 1440000
Best mean reward: -10.39 - Last mean reward per episode: -10.73
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 176          |
|    time_elapsed         | 41693        |
|    total_timesteps      | 1441792      |
| train/                  |              |
|    approx_kl            | 0.0006478058 |
|    clip_fraction        | 0.0248       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.11        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.264        |
|    n_updates            | 1925         |
|    policy_gradient_loss | -0.000534    |
|    std                  | 0.693        |
|    value_loss           | 0.319        |
------------------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -10.7       |
| time/                   |             |
|    fps                  | 34          |
|    iterations           | 177         |
|    time_elapsed         | 41932       |
|    total_timesteps      | 1449984     |
| train/                  |             |
|    approx_kl            | 0.000653908 |
|    clip_fraction        | 0.0274      |
|    clip_range           | 0.075       |
|    entropy_loss         | -3.09       |
|    explained_variance   | 0           |
|    learning_rate        | 0.000168    |
|    loss                 | 0.314       |
|    n_updates            | 1936        |
|    policy_gradient_loss | -0.000705   |
|    std                  | 0.688       |
|    value_loss           | 0.34        |
-----------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 178          |
|    time_elapsed         | 42171        |
|    total_timesteps      | 1458176      |
| train/                  |              |
|    approx_kl            | 0.0006652997 |
|    clip_fraction        | 0.0427       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.09        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.214        |
|    n_updates            | 1947         |
|    policy_gradient_loss | -0.000977    |
|    std                  | 0.689        |
|    value_loss           | 0.31         |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 179          |
|    time_elapsed         | 42407        |
|    total_timesteps      | 1466368      |
| train/                  |              |
|    approx_kl            | 0.0005781599 |
|    clip_fraction        | 0.0341       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.09        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.236        |
|    n_updates            | 1958         |
|    policy_gradient_loss | -0.000675    |
|    std                  | 0.689        |
|    value_loss           | 0.296        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 180          |
|    time_elapsed         | 42647        |
|    total_timesteps      | 1474560      |
| train/                  |              |
|    approx_kl            | 0.0005629844 |
|    clip_fraction        | 0.0157       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.09        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.254        |
|    n_updates            | 1969         |
|    policy_gradient_loss | -0.000147    |
|    std                  | 0.688        |
|    value_loss           | 0.276        |
------------------------------------------
Num timesteps: 1480000
Best mean reward: -10.39 - Last mean reward per episode: -10.82
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 181           |
|    time_elapsed         | 42883         |
|    total_timesteps      | 1482752       |
| train/                  |               |
|    approx_kl            | 0.00086928625 |
|    clip_fraction        | 0.0401        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.08         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.197         |
|    n_updates            | 1980          |
|    policy_gradient_loss | -0.000969     |
|    std                  | 0.686         |
|    value_loss           | 0.262         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.7         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 182           |
|    time_elapsed         | 43126         |
|    total_timesteps      | 1490944       |
| train/                  |               |
|    approx_kl            | 0.00059087947 |
|    clip_fraction        | 0.0277        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.07         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.285         |
|    n_updates            | 1991          |
|    policy_gradient_loss | -0.000595     |
|    std                  | 0.682         |
|    value_loss           | 0.326         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11           |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 183           |
|    time_elapsed         | 43370         |
|    total_timesteps      | 1499136       |
| train/                  |               |
|    approx_kl            | 0.00051126163 |
|    clip_fraction        | 0.0221        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.05         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.239         |
|    n_updates            | 2002          |
|    policy_gradient_loss | -0.000364     |
|    std                  | 0.68          |
|    value_loss           | 0.304         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 184           |
|    time_elapsed         | 43605         |
|    total_timesteps      | 1507328       |
| train/                  |               |
|    approx_kl            | 0.00048727597 |
|    clip_fraction        | 0.0255        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.05         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.204         |
|    n_updates            | 2013          |
|    policy_gradient_loss | -0.000257     |
|    std                  | 0.679         |
|    value_loss           | 0.322         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 185           |
|    time_elapsed         | 43852         |
|    total_timesteps      | 1515520       |
| train/                  |               |
|    approx_kl            | 0.00046752975 |
|    clip_fraction        | 0.0197        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.05         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.246         |
|    n_updates            | 2024          |
|    policy_gradient_loss | -0.000145     |
|    std                  | 0.68          |
|    value_loss           | 0.324         |
-------------------------------------------
Num timesteps: 1520000
Best mean reward: -10.39 - Last mean reward per episode: -10.06
Saving new best model to 17April2022/mainFull/best_model
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument "destination" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.5        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 186          |
|    time_elapsed         | 44091        |
|    total_timesteps      | 1523712      |
| train/                  |              |
|    approx_kl            | 0.0006784155 |
|    clip_fraction        | 0.0377       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.04        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.175        |
|    n_updates            | 2035         |
|    policy_gradient_loss | -0.000884    |
|    std                  | 0.679        |
|    value_loss           | 0.28         |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.5         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 187           |
|    time_elapsed         | 44327         |
|    total_timesteps      | 1531904       |
| train/                  |               |
|    approx_kl            | 0.00058453256 |
|    clip_fraction        | 0.0257        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.04         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.242         |
|    n_updates            | 2046          |
|    policy_gradient_loss | -0.000425     |
|    std                  | 0.678         |
|    value_loss           | 0.309         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.2         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 188           |
|    time_elapsed         | 44562         |
|    total_timesteps      | 1540096       |
| train/                  |               |
|    approx_kl            | 0.00051802327 |
|    clip_fraction        | 0.0194        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.04         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.182         |
|    n_updates            | 2057          |
|    policy_gradient_loss | -0.000308     |
|    std                  | 0.678         |
|    value_loss           | 0.306         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 189           |
|    time_elapsed         | 44800         |
|    total_timesteps      | 1548288       |
| train/                  |               |
|    approx_kl            | 0.00038915288 |
|    clip_fraction        | 0.0292        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.03         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.191         |
|    n_updates            | 2068          |
|    policy_gradient_loss | -0.000542     |
|    std                  | 0.677         |
|    value_loss           | 0.259         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -9.83         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 190           |
|    time_elapsed         | 45038         |
|    total_timesteps      | 1556480       |
| train/                  |               |
|    approx_kl            | 0.00064349954 |
|    clip_fraction        | 0.0257        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.03         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.223         |
|    n_updates            | 2079          |
|    policy_gradient_loss | -0.000426     |
|    std                  | 0.677         |
|    value_loss           | 0.323         |
-------------------------------------------
Num timesteps: 1560000
Best mean reward: -10.06 - Last mean reward per episode: -10.48
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 191          |
|    time_elapsed         | 45276        |
|    total_timesteps      | 1564672      |
| train/                  |              |
|    approx_kl            | 0.0005374013 |
|    clip_fraction        | 0.0258       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.02        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.236        |
|    n_updates            | 2090         |
|    policy_gradient_loss | -0.000563    |
|    std                  | 0.675        |
|    value_loss           | 0.328        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 192          |
|    time_elapsed         | 45514        |
|    total_timesteps      | 1572864      |
| train/                  |              |
|    approx_kl            | 0.0006183719 |
|    clip_fraction        | 0.0209       |
|    clip_range           | 0.075        |
|    entropy_loss         | -3.02        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.23         |
|    n_updates            | 2101         |
|    policy_gradient_loss | -0.000117    |
|    std                  | 0.676        |
|    value_loss           | 0.318        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 193           |
|    time_elapsed         | 45752         |
|    total_timesteps      | 1581056       |
| train/                  |               |
|    approx_kl            | 0.00040589314 |
|    clip_fraction        | 0.0194        |
|    clip_range           | 0.075         |
|    entropy_loss         | -3.01         |
|    explained_variance   | 1.19e-07      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.256         |
|    n_updates            | 2112          |
|    policy_gradient_loss | -0.000446     |
|    std                  | 0.67          |
|    value_loss           | 0.315         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 194           |
|    time_elapsed         | 45987         |
|    total_timesteps      | 1589248       |
| train/                  |               |
|    approx_kl            | 0.00055408856 |
|    clip_fraction        | 0.0199        |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.99         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.272         |
|    n_updates            | 2123          |
|    policy_gradient_loss | -0.000347     |
|    std                  | 0.666         |
|    value_loss           | 0.294         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.2        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 195          |
|    time_elapsed         | 46226        |
|    total_timesteps      | 1597440      |
| train/                  |              |
|    approx_kl            | 0.0004440859 |
|    clip_fraction        | 0.0135       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.98        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.236        |
|    n_updates            | 2134         |
|    policy_gradient_loss | -0.000192    |
|    std                  | 0.664        |
|    value_loss           | 0.331        |
------------------------------------------
Num timesteps: 1600000
Best mean reward: -10.06 - Last mean reward per episode: -10.37
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 196           |
|    time_elapsed         | 46468         |
|    total_timesteps      | 1605632       |
| train/                  |               |
|    approx_kl            | 0.00061763125 |
|    clip_fraction        | 0.0287        |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.97         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.258         |
|    n_updates            | 2145          |
|    policy_gradient_loss | -0.000627     |
|    std                  | 0.662         |
|    value_loss           | 0.296         |
-------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.4         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 197           |
|    time_elapsed         | 46713         |
|    total_timesteps      | 1613824       |
| train/                  |               |
|    approx_kl            | 0.00056631817 |
|    clip_fraction        | 0.0343        |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.97         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.279         |
|    n_updates            | 2156          |
|    policy_gradient_loss | -0.000586     |
|    std                  | 0.663         |
|    value_loss           | 0.333         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.6        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 198          |
|    time_elapsed         | 46954        |
|    total_timesteps      | 1622016      |
| train/                  |              |
|    approx_kl            | 0.0002470853 |
|    clip_fraction        | 0.0145       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.96        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.229        |
|    n_updates            | 2167         |
|    policy_gradient_loss | -5.93e-05    |
|    std                  | 0.661        |
|    value_loss           | 0.311        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.6         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 199           |
|    time_elapsed         | 47202         |
|    total_timesteps      | 1630208       |
| train/                  |               |
|    approx_kl            | 0.00041064582 |
|    clip_fraction        | 0.016         |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.95         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.226         |
|    n_updates            | 2178          |
|    policy_gradient_loss | -0.000266     |
|    std                  | 0.661         |
|    value_loss           | 0.297         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.7        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 200          |
|    time_elapsed         | 47455        |
|    total_timesteps      | 1638400      |
| train/                  |              |
|    approx_kl            | 0.0006132065 |
|    clip_fraction        | 0.0188       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.95        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.265        |
|    n_updates            | 2189         |
|    policy_gradient_loss | -0.000373    |
|    std                  | 0.658        |
|    value_loss           | 0.358        |
------------------------------------------
Num timesteps: 1640000
Best mean reward: -10.06 - Last mean reward per episode: -10.81
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.9         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 201           |
|    time_elapsed         | 47694         |
|    total_timesteps      | 1646592       |
| train/                  |               |
|    approx_kl            | 0.00070962775 |
|    clip_fraction        | 0.029         |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.94         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000168      |
|    loss                 | 0.211         |
|    n_updates            | 2200          |
|    policy_gradient_loss | -0.000549     |
|    std                  | 0.657         |
|    value_loss           | 0.312         |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.9        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 202          |
|    time_elapsed         | 47934        |
|    total_timesteps      | 1654784      |
| train/                  |              |
|    approx_kl            | 0.0005896832 |
|    clip_fraction        | 0.0332       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.93        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000168     |
|    loss                 | 0.237        |
|    n_updates            | 2211         |
|    policy_gradient_loss | -0.000723    |
|    std                  | 0.657        |
|    value_loss           | 0.303        |
------------------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -10.8         |
| time/                   |               |
|    fps                  | 34            |
|    iterations           | 203           |
|    time_elapsed         | 48176         |
|    total_timesteps      | 1662976       |
| train/                  |               |
|    approx_kl            | 0.00041456893 |
|    clip_fraction        | 0.0136        |
|    clip_range           | 0.075         |
|    entropy_loss         | -2.92         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.287         |
|    n_updates            | 2222          |
|    policy_gradient_loss | -0.000198     |
|    std                  | 0.652         |
|    value_loss           | 0.33          |
-------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 204          |
|    time_elapsed         | 48419        |
|    total_timesteps      | 1671168      |
| train/                  |              |
|    approx_kl            | 0.0005390418 |
|    clip_fraction        | 0.0199       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.9         |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.197        |
|    n_updates            | 2233         |
|    policy_gradient_loss | -0.000306    |
|    std                  | 0.65         |
|    value_loss           | 0.299        |
------------------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.4        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 205          |
|    time_elapsed         | 48663        |
|    total_timesteps      | 1679360      |
| train/                  |              |
|    approx_kl            | 0.0004873394 |
|    clip_fraction        | 0.0215       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.89        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.245        |
|    n_updates            | 2244         |
|    policy_gradient_loss | -0.000375    |
|    std                  | 0.648        |
|    value_loss           | 0.309        |
------------------------------------------
Num timesteps: 1680000
Best mean reward: -10.06 - Last mean reward per episode: -10.17
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -10.3        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 206          |
|    time_elapsed         | 48909        |
|    total_timesteps      | 1687552      |
| train/                  |              |
|    approx_kl            | 0.0007421689 |
|    clip_fraction        | 0.0382       |
|    clip_range           | 0.075        |
|    entropy_loss         | -2.88        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000168     |
|    loss                 | 0.229        |
|    n_updates            | 2255         |
|    policy_gradient_loss | -0.000708    |
|    std                  | 0.646        |
|    value_loss           | 0.304        |
------------------------------------------
^CTraceback (most recent call last):
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/mainFull_V02.py", line 211, in <module>
    model.learn(total_timesteps=int(OPTIMIZED_N_TIMESTEPS), callback=callback)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/ppo/ppo.py", line 299, in learn
    return super(PPO, self).learn(
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 250, in learn
    continue_training = self.collect_rollouts(self.env, callback, self.rollout_buffer, n_rollout_steps=self.n_steps)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py", line 178, in collect_rollouts
    new_obs, rewards, dones, infos = env.step(clipped_actions)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py", line 162, in step
    return self.step_wait()
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/vec_env/vec_frame_stack.py", line 48, in step_wait
    observations, rewards, dones, infos = self.venv.step_wait()
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py", line 43, in step_wait
    obs, self.buf_rews[env_idx], self.buf_dones[env_idx], self.buf_infos[env_idx] = self.envs[env_idx].step(
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/pandaWrapperBW_D_0.py", line 90, in step
    img, depth = self.env.render(mode = 'rgb_array',width = 100, height= 100, distance = 1, 
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/gym/core.py", line 254, in render
    return self.env.render(mode, **kwargs)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/gym/core.py", line 254, in render
    return self.env.render(mode, **kwargs)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/panda_gym/envs/core.py", line 293, in render
    return self.sim.render(
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py", line 112, in render
    (_, _, px, depth, _) = self.physics_client.getCameraImage(
KeyboardInterrupt

(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ exit
exit

Script done on 2022-04-18 11:49:29-04:00 [COMMAND_EXIT_CODE="130"]
