Script started on 2022-04-17 11:16:09-04:00 [TERM="xterm-256color" TTY="/dev/pts/1" COLUMNS="80" LINES="24"]
bash: devel/setup.bash: No such file or directory
]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew/17April2022[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew/17April2022[00m$ cd .. [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[K.
]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ conda activate rl _env
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ ls
[0m[01;34m11April2022[0m       linearSchedule.py  optunaCust_V01.py       [01;34m__pycache__[0m
[01;34m13April2022[0m       [01;34mlogs[0m               optunaCust_V02.py       register.py
[01;34m14April2022[0m       mainFull_V00.py    pandaCust.py            timer.py
[01;34m16April2022[0m       mainFull_V01.py    pandareachdepth.py      [01;34mtmp[0m
[01;34m17April2022[0m       mainMulti.py       pandaWrapperBW_D_0.py   [01;34mtmpMulti[0m
[01;34m6April2022[0m        mainOpt_V01.py     pandaWrapperBW.py       [01;34mtmpTestMulti[0m
check             mainOpt_V02.py     pandaWrapper.py         [01;34mvideos[0m
customCnn_V01.py  multiCompare.py    pickPlaceVectOptV01.py
customCnn_V02.py  optimize_V01.py    PPANDPUSH_VECT.py
[01;34mimages[0m            optimize_V02.py    pybulletCust.py
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ ptyhin[K[K[K[K[Kythin3  mainOpt_V02.py 

Command 'pythin3' not found, did you mean:

  command 'python3' from deb python3 (3.8.2-0ubuntu2)

Try: sudo apt install <deb name>

(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ pythin3 mainOpt_V02.py [A[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[C[Cn3 ma[1P[A(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ [C[C[C[Con3 m[1@a[A(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ [C[C[C[C[C

pybullet build time: Dec  1 2021 18:34:28
plotly:  5.6.0
optuna:  2.10.0
Traceback (most recent call last):
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/mainOpt_V02.py", line 12, in <module>
    from optunaCust_V02 import OptunaFunc, TrialEvalCallback
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/optunaCust_V02.py", line 64, in <module>
    os.mkdir(os.path.join(path_dir, directory))
FileNotFoundError: [Errno 2] No such file or directory: '/home/hjkwon/scripts/stable_baselines/pandaAndrew/17April2022/images/cnnNetworkSearch/'
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ python3 mainOpt_V02.py 
pybullet build time: Dec  1 2021 18:34:28
plotly:  5.6.0
optuna:  2.10.0
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/googlenet.py:46: FutureWarning: The default weight initialization of GoogleNet will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/torchvision/models/inception.py:44: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
[32m[I 2022-04-17 11:17:44,664][0m A new study created in memory with name: no-name-d360a14f-62d5-4239-87b3-c599ac6291e7[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.969706189981343, 'gae_lambda': 0.9407414342022105, 'learning_rate': 0.0002967756415181469, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 8, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.6        |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 2            |
|    time_elapsed         | 395          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0005789003 |
|    clip_fraction        | 0.0419       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.000561    |
|    learning_rate        | 0.000297     |
|    loss                 | 0.799        |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.00054     |
|    std                  | 1            |
|    value_loss           | 1.14         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.78 +/- 2.49
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 50          |
|    mean_reward          | -9.78       |
|    success_rate         | 0           |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.000810815 |
|    clip_fraction        | 0.052       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | -2.5e-06    |
|    learning_rate        | 0.000297    |
|    loss                 | 0.804       |
|    n_updates            | 16          |
|    policy_gradient_loss | -0.00165    |
|    std                  | 0.998       |
|    value_loss           | 1.03        |
-----------------------------------------
New best mean reward!
Elapsed time: 532.7573 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 38       |
|    iterations      | 3        |
|    time_elapsed    | 632      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.4         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 4             |
|    time_elapsed         | 856           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00057760114 |
|    clip_fraction        | 0.0414        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -4.77e-07     |
|    learning_rate        | 0.000297      |
|    loss                 | 0.561         |
|    n_updates            | 24            |
|    policy_gradient_loss | -0.000975     |
|    std                  | 0.998         |
|    value_loss           | 0.82          |
-------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 904.9501 seconds
[32m[I 2022-04-17 11:32:49,615][0m Trial 0 finished with value: -9.782505500000003 and parameters: {'gamma': 0.969706189981343, 'gae_lambda': 0.9407414342022105, 'lr': 0.0002967756415181469, 'n_epochs': 8, 'net_arch_width_int': 6, 'net_arch_depth': 4}. Best is trial 0 with value: -9.782505500000003.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9181692657478081, 'gae_lambda': 0.9591652702646867, 'learning_rate': 0.024505948187247616, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 50        |
|    ep_rew_mean          | -24.6     |
| time/                   |           |
|    fps                  | 38        |
|    iterations           | 2         |
|    time_elapsed         | 426       |
|    total_timesteps      | 16384     |
| train/                  |           |
|    approx_kl            | 164.71927 |
|    clip_fraction        | 0.997     |
|    clip_range           | 0.075     |
|    entropy_loss         | -4.91     |
|    explained_variance   | 0.0033    |
|    learning_rate        | 0.0245    |
|    loss                 | 0.869     |
|    n_updates            | 13        |
|    policy_gradient_loss | 0.37      |
|    std                  | 1.26      |
|    value_loss           | 1.04      |
---------------------------------------
Eval num_timesteps=20000, episode_reward=-23.68 +/- 3.40
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
---------------------------------------
| eval/                   |           |
|    mean_ep_length       | 50        |
|    mean_reward          | -23.7     |
|    success_rate         | 0         |
| time/                   |           |
|    total_timesteps      | 20000     |
| train/                  |           |
|    approx_kl            | 723.4573  |
|    clip_fraction        | 0.998     |
|    clip_range           | 0.075     |
|    entropy_loss         | -5.09     |
|    explained_variance   | -1.19e-07 |
|    learning_rate        | 0.0245    |
|    loss                 | 1.29      |
|    n_updates            | 26        |
|    policy_gradient_loss | 0.38      |
|    std                  | 1.37      |
|    value_loss           | 1.08      |
---------------------------------------
New best mean reward!
Elapsed time: 585.4080 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -24.6    |
| time/              |          |
|    fps             | 35       |
|    iterations      | 3        |
|    time_elapsed    | 686      |
|    total_timesteps | 24576    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 50       |
|    ep_rew_mean          | -26.1    |
| time/                   |          |
|    fps                  | 35       |
|    iterations           | 4        |
|    time_elapsed         | 927      |
|    total_timesteps      | 32768    |
| train/                  |          |
|    approx_kl            | 5811.652 |
|    clip_fraction        | 0.998    |
|    clip_range           | 0.075    |
|    entropy_loss         | -4.89    |
|    explained_variance   | 0        |
|    learning_rate        | 0.0245   |
|    loss                 | 0.955    |
|    n_updates            | 39       |
|    policy_gradient_loss | 0.374    |
|    std                  | 1.45     |
|    value_loss           | 0.785    |
--------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 998.2452 seconds
[32m[I 2022-04-17 11:49:27,860][0m Trial 1 finished with value: -23.6756702 and parameters: {'gamma': 0.9181692657478081, 'gae_lambda': 0.9591652702646867, 'lr': 0.024505948187247616, 'n_epochs': 13, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 0 with value: -9.782505500000003.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.965129298509684, 'gae_lambda': 0.8608598972714903, 'learning_rate': 0.0410078298591782, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
---------------------------------------
| rollout/                |           |
|    ep_len_mean          | 50        |
|    ep_rew_mean          | -24.7     |
| time/                   |           |
|    fps                  | 39        |
|    iterations           | 2         |
|    time_elapsed         | 411       |
|    total_timesteps      | 16384     |
| train/                  |           |
|    approx_kl            | 138.09401 |
|    clip_fraction        | 0.997     |
|    clip_range           | 0.075     |
|    entropy_loss         | -5.51     |
|    explained_variance   | 0.00314   |
|    learning_rate        | 0.041     |
|    loss                 | 0.611     |
|    n_updates            | 13        |
|    policy_gradient_loss | 0.372     |
|    std                  | 1.55      |
|    value_loss           | 0.566     |
---------------------------------------
Eval num_timesteps=20000, episode_reward=-47.65 +/- 3.68
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
--------------------------------------
| eval/                   |          |
|    mean_ep_length       | 50       |
|    mean_reward          | -47.7    |
|    success_rate         | 0        |
| time/                   |          |
|    total_timesteps      | 20000    |
| train/                  |          |
|    approx_kl            | 733.5342 |
|    clip_fraction        | 0.997    |
|    clip_range           | 0.075    |
|    entropy_loss         | -5.66    |
|    explained_variance   | 0        |
|    learning_rate        | 0.041    |
|    loss                 | 0.812    |
|    n_updates            | 26       |
|    policy_gradient_loss | 0.368    |
|    std                  | 1.98     |
|    value_loss           | 0.673    |
--------------------------------------
New best mean reward!
Elapsed time: 565.8908 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -49.3    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 3        |
|    time_elapsed    | 658      |
|    total_timesteps | 24576    |
---------------------------------
--------------------------------------
| rollout/                |          |
|    ep_len_mean          | 50       |
|    ep_rew_mean          | -46.3    |
| time/                   |          |
|    fps                  | 36       |
|    iterations           | 4        |
|    time_elapsed         | 897      |
|    total_timesteps      | 32768    |
| train/                  |          |
|    approx_kl            | 826.8819 |
|    clip_fraction        | 0.997    |
|    clip_range           | 0.075    |
|    entropy_loss         | -6.5     |
|    explained_variance   | 0        |
|    learning_rate        | 0.041    |
|    loss                 | 2.75     |
|    n_updates            | 39       |
|    policy_gradient_loss | 0.39     |
|    std                  | 2.48     |
|    value_loss           | 3.48     |
--------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 966.5226 seconds
[32m[I 2022-04-17 12:05:34,384][0m Trial 2 finished with value: -47.6522968 and parameters: {'gamma': 0.965129298509684, 'gae_lambda': 0.8608598972714903, 'lr': 0.0410078298591782, 'n_epochs': 13, 'net_arch_width_int': 6, 'net_arch_depth': 4}. Best is trial 0 with value: -9.782505500000003.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9816306906777021, 'gae_lambda': 0.8210798868989126, 'learning_rate': 0.00036779262545422875, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 1        |
|    time_elapsed    | 173      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -12.7       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 2           |
|    time_elapsed         | 414         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.001101779 |
|    clip_fraction        | 0.0824      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | -0.00963    |
|    learning_rate        | 0.000368    |
|    loss                 | 0.158       |
|    n_updates            | 13          |
|    policy_gradient_loss | -0.00116    |
|    std                  | 0.995       |
|    value_loss           | 0.235       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-8.80 +/- 2.72
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.8         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0007907222 |
|    clip_fraction        | 0.0597       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | -0.0011      |
|    learning_rate        | 0.000368     |
|    loss                 | 0.189        |
|    n_updates            | 26           |
|    policy_gradient_loss | -0.000988    |
|    std                  | 0.995        |
|    value_loss           | 0.266        |
------------------------------------------
New best mean reward!
Elapsed time: 573.3379 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13.3    |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 671      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 4            |
|    time_elapsed         | 917          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0008648611 |
|    clip_fraction        | 0.0705       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | -0.00019     |
|    learning_rate        | 0.000368     |
|    loss                 | 0.212        |
|    n_updates            | 39           |
|    policy_gradient_loss | -0.00193     |
|    std                  | 0.992        |
|    value_loss           | 0.288        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 987.1307 seconds
[32m[I 2022-04-17 12:22:01,515][0m Trial 3 finished with value: -8.797671000000001 and parameters: {'gamma': 0.9816306906777021, 'gae_lambda': 0.8210798868989126, 'lr': 0.00036779262545422875, 'n_epochs': 13, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 3 with value: -8.797671000000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9392322546736359, 'gae_lambda': 0.9112236693415027, 'learning_rate': 0.005218659137685901, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 6, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64], 'vf': [64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -12.3       |
| time/                   |             |
|    fps                  | 42          |
|    iterations           | 2           |
|    time_elapsed         | 384         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.002463283 |
|    clip_fraction        | 0.236       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.26       |
|    explained_variance   | -0.00847    |
|    learning_rate        | 0.00522     |
|    loss                 | 0.363       |
|    n_updates            | 6           |
|    policy_gradient_loss | 0.00351     |
|    std                  | 1.01        |
|    value_loss           | 0.478       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-10.97 +/- 3.30
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -11          |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0010014718 |
|    clip_fraction        | 0.171        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.27        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00522      |
|    loss                 | 0.317        |
|    n_updates            | 12           |
|    policy_gradient_loss | 0.00314      |
|    std                  | 0.997        |
|    value_loss           | 0.374        |
------------------------------------------
New best mean reward!
Elapsed time: 506.7876 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 40       |
|    iterations      | 3        |
|    time_elapsed    | 603      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.5        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 4            |
|    time_elapsed         | 810          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0018811574 |
|    clip_fraction        | 0.168        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00522      |
|    loss                 | 0.268        |
|    n_updates            | 18           |
|    policy_gradient_loss | 0.00178      |
|    std                  | 0.992        |
|    value_loss           | 0.348        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 843.3842 seconds
[32m[I 2022-04-17 12:36:04,900][0m Trial 4 finished with value: -10.968664200000001 and parameters: {'gamma': 0.9392322546736359, 'gae_lambda': 0.9112236693415027, 'lr': 0.005218659137685901, 'n_epochs': 6, 'net_arch_width_int': 6, 'net_arch_depth': 3}. Best is trial 3 with value: -8.797671000000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9975364439109425, 'gae_lambda': 0.8040508871615567, 'learning_rate': 5.359152400078134e-06, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128], 'vf': [128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 47       |
|    iterations      | 1        |
|    time_elapsed    | 173      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.5        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 403          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007764342 |
|    clip_fraction        | 0.0397       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.00839      |
|    learning_rate        | 5.36e-06     |
|    loss                 | 0.159        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00153     |
|    std                  | 1            |
|    value_loss           | 0.407        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.55 +/- 2.30
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -9.55         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00064162764 |
|    clip_fraction        | 0.018         |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.0046        |
|    learning_rate        | 5.36e-06      |
|    loss                 | 0.158         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.000866     |
|    std                  | 1             |
|    value_loss           | 0.369         |
-------------------------------------------
New best mean reward!
Elapsed time: 548.3846 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
directory---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 3        |
|    time_elapsed    | 648      |
|    total_timesteps | 24576    |
---------------------------------
directory------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 4            |
|    time_elapsed         | 885          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0006253326 |
|    clip_fraction        | 0.0202       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.00437      |
|    learning_rate        | 5.36e-06     |
|    loss                 | 0.195        |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.001       |
|    std                  | 1            |
|    value_loss           | 0.344        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 940.8267 seconds
[32m[I 2022-04-17 12:51:45,727][0m Trial 5 finished with value: -9.5479417 and parameters: {'gamma': 0.9975364439109425, 'gae_lambda': 0.8040508871615567, 'lr': 5.359152400078134e-06, 'n_epochs': 10, 'net_arch_width_int': 7, 'net_arch_depth': 3}. Best is trial 3 with value: -8.797671000000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9955387535498866, 'gae_lambda': 0.8063530024598979, 'learning_rate': 0.00016528023284414782, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 181      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12          |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 413          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007648106 |
|    clip_fraction        | 0.0508       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00794      |
|    learning_rate        | 0.000165     |
|    loss                 | 0.241        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000751    |
|    std                  | 0.999        |
|    value_loss           | 0.3          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.96 +/- 3.22
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 50          |
|    mean_reward          | -7.96       |
|    success_rate         | 0           |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.000599202 |
|    clip_fraction        | 0.0229      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.00086     |
|    learning_rate        | 0.000165    |
|    loss                 | 0.16        |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.000486   |
|    std                  | 0.996       |
|    value_loss           | 0.238       |
-----------------------------------------
New best mean reward!
Elapsed time: 559.8402 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 37       |
|    iterations      | 3        |
|    time_elapsed    | 659      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 893          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0006161526 |
|    clip_fraction        | 0.0295       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 4.7e-05      |
|    learning_rate        | 0.000165     |
|    loss                 | 0.173        |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.000751    |
|    std                  | 0.992        |
|    value_loss           | 0.258        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 948.2372 seconds
[32m[I 2022-04-17 13:07:33,966][0m Trial 6 finished with value: -7.961279900000001 and parameters: {'gamma': 0.9955387535498866, 'gae_lambda': 0.8063530024598979, 'lr': 0.00016528023284414782, 'n_epochs': 10, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 6 with value: -7.961279900000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.902644761610593, 'gae_lambda': 0.8481054528628894, 'learning_rate': 2.352233849036561e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 8, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128], 'vf': [128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 401          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007544819 |
|    clip_fraction        | 0.0478       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00192     |
|    learning_rate        | 2.35e-05     |
|    loss                 | 0.138        |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.00159     |
|    std                  | 0.999        |
|    value_loss           | 0.203        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.66 +/- 3.02
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.66        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0008629069 |
|    clip_fraction        | 0.0368       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.0602       |
|    learning_rate        | 2.35e-05     |
|    loss                 | 0.105        |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.0013      |
|    std                  | 0.999        |
|    value_loss           | 0.157        |
------------------------------------------
New best mean reward!
Elapsed time: 539.0680 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13.2    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 3        |
|    time_elapsed    | 640      |
|    total_timesteps | 24576    |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -11.7       |
| time/                   |             |
|    fps                  | 37          |
|    iterations           | 4           |
|    time_elapsed         | 882         |
|    total_timesteps      | 32768       |
| train/                  |             |
|    approx_kl            | 0.000736646 |
|    clip_fraction        | 0.0531      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.225       |
|    learning_rate        | 2.35e-05    |
|    loss                 | 0.0969      |
|    n_updates            | 24          |
|    policy_gradient_loss | -0.00177    |
|    std                  | 0.999       |
|    value_loss           | 0.169       |
-----------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 936.0876 seconds
[32m[I 2022-04-17 13:23:10,055][0m Trial 7 finished with value: -9.6614894 and parameters: {'gamma': 0.902644761610593, 'gae_lambda': 0.8481054528628894, 'lr': 2.352233849036561e-05, 'n_epochs': 8, 'net_arch_width_int': 7, 'net_arch_depth': 3}. Best is trial 6 with value: -7.961279900000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9454048116665643, 'gae_lambda': 0.8842225733240223, 'learning_rate': 9.257666105124382e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 44       |
|    iterations      | 1        |
|    time_elapsed    | 183      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 422          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007109783 |
|    clip_fraction        | 0.047        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00404      |
|    learning_rate        | 9.26e-05     |
|    loss                 | 0.231        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000949    |
|    std                  | 0.997        |
|    value_loss           | 0.363        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-6.58 +/- 2.32
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -6.58         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00078206335 |
|    clip_fraction        | 0.0522        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.0272        |
|    learning_rate        | 9.26e-05      |
|    loss                 | 0.277         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00119      |
|    std                  | 0.997         |
|    value_loss           | 0.296         |
-------------------------------------------
New best mean reward!
Elapsed time: 567.9558 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 667      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.1         |
| time/                   |               |
|    fps                  | 36            |
|    iterations           | 4             |
|    time_elapsed         | 898           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00071533397 |
|    clip_fraction        | 0.0363        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.0292        |
|    learning_rate        | 9.26e-05      |
|    loss                 | 0.214         |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.000661     |
|    std                  | 0.997         |
|    value_loss           | 0.255         |
-------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 954.5716 seconds
[32m[I 2022-04-17 13:39:04,627][0m Trial 8 finished with value: -6.5801666999999995 and parameters: {'gamma': 0.9454048116665643, 'gae_lambda': 0.8842225733240223, 'lr': 9.257666105124382e-05, 'n_epochs': 10, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 8 with value: -6.5801666999999995.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9407574574490746, 'gae_lambda': 0.8904601547301361, 'learning_rate': 4.206078543337364e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 6, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64], 'vf': [64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 179      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.7         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 2             |
|    time_elapsed         | 399           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00090102165 |
|    clip_fraction        | 0.0562        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.00579       |
|    learning_rate        | 4.21e-05      |
|    loss                 | 0.274         |
|    n_updates            | 6             |
|    policy_gradient_loss | -0.00171      |
|    std                  | 0.999         |
|    value_loss           | 0.379         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.72 +/- 2.96
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -9.72         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00067818665 |
|    clip_fraction        | 0.0299        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.0181        |
|    learning_rate        | 4.21e-05      |
|    loss                 | 0.207         |
|    n_updates            | 12            |
|    policy_gradient_loss | -0.000985     |
|    std                  | 0.998         |
|    value_loss           | 0.415         |
-------------------------------------------
New best mean reward!
Elapsed time: 528.1213 seconds
[32m[I 2022-04-17 13:47:53,016][0m Trial 9 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.921708852636787, 'gae_lambda': 0.984671572296977, 'learning_rate': 0.0018140661166890096, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 174      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 409          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0013431166 |
|    clip_fraction        | 0.174        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00334     |
|    learning_rate        | 0.00181      |
|    loss                 | 0.802        |
|    n_updates            | 10           |
|    policy_gradient_loss | 0.00246      |
|    std                  | 1.01         |
|    value_loss           | 1.2          |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-12.33 +/- 2.67
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -12.3        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0012156244 |
|    clip_fraction        | 0.134        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.28        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00181      |
|    loss                 | 0.487        |
|    n_updates            | 20           |
|    policy_gradient_loss | 0.00136      |
|    std                  | 1.01         |
|    value_loss           | 0.647        |
------------------------------------------
New best mean reward!
Elapsed time: 562.7575 seconds
[32m[I 2022-04-17 13:57:16,053][0m Trial 10 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9534789067934243, 'gae_lambda': 0.8500322900829949, 'learning_rate': 5.379090992578957e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    fps             | 44       |
|    iterations      | 1        |
|    time_elapsed    | 182      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.3         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 2             |
|    time_elapsed         | 422           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00056976476 |
|    clip_fraction        | 0.0247        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.0011        |
|    learning_rate        | 5.38e-05      |
|    loss                 | 0.16          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000551     |
|    std                  | 1             |
|    value_loss           | 0.232         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.59 +/- 3.24
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 50          |
|    mean_reward          | -9.59       |
|    success_rate         | 0           |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.000751415 |
|    clip_fraction        | 0.0576      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0.183       |
|    learning_rate        | 5.38e-05    |
|    loss                 | 0.131       |
|    n_updates            | 20          |
|    policy_gradient_loss | -0.00161    |
|    std                  | 0.999       |
|    value_loss           | 0.223       |
-----------------------------------------
New best mean reward!
Elapsed time: 572.9901 seconds
[32m[I 2022-04-17 14:06:49,467][0m Trial 11 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.992601496741308, 'gae_lambda': 0.8789552297223628, 'learning_rate': 0.0001678993231767122, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.1    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 179      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.1         |
| time/                   |               |
|    fps                  | 38            |
|    iterations           | 2             |
|    time_elapsed         | 431           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00057883444 |
|    clip_fraction        | 0.0381        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -0.00588      |
|    learning_rate        | 0.000168      |
|    loss                 | 0.315         |
|    n_updates            | 11            |
|    policy_gradient_loss | -0.000607     |
|    std                  | 0.999         |
|    value_loss           | 0.49          |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-6.50 +/- 2.87
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -6.5         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0007009916 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 1.44e-05     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.355        |
|    n_updates            | 22           |
|    policy_gradient_loss | -0.000915    |
|    std                  | 0.997        |
|    value_loss           | 0.589        |
------------------------------------------
New best mean reward!
Elapsed time: 586.0233 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    fps             | 35       |
|    iterations      | 3        |
|    time_elapsed    | 687      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 35            |
|    iterations           | 4             |
|    time_elapsed         | 930           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00072687597 |
|    clip_fraction        | 0.0426        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.24         |
|    explained_variance   | -0.000459     |
|    learning_rate        | 0.000168      |
|    loss                 | 0.404         |
|    n_updates            | 33            |
|    policy_gradient_loss | -0.000655     |
|    std                  | 0.994         |
|    value_loss           | 0.642         |
-------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 992.3098 seconds
[32m[I 2022-04-17 14:23:21,778][0m Trial 12 finished with value: -6.4980716 and parameters: {'gamma': 0.992601496741308, 'gae_lambda': 0.8789552297223628, 'lr': 0.0001678993231767122, 'n_epochs': 11, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9584811397786247, 'gae_lambda': 0.8902971219851689, 'learning_rate': 0.0015253041470346008, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 44       |
|    iterations      | 1        |
|    time_elapsed    | 183      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.5        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 430          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0013690165 |
|    clip_fraction        | 0.153        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.00293     |
|    learning_rate        | 0.00153      |
|    loss                 | 0.319        |
|    n_updates            | 11           |
|    policy_gradient_loss | 0.00149      |
|    std                  | 0.994        |
|    value_loss           | 0.461        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.67 +/- 2.90
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.67        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0012881109 |
|    clip_fraction        | 0.0876       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00153      |
|    loss                 | 0.302        |
|    n_updates            | 22           |
|    policy_gradient_loss | 0.000859     |
|    std                  | 0.991        |
|    value_loss           | 0.407        |
------------------------------------------
New best mean reward!
Elapsed time: 587.9124 seconds
[32m[I 2022-04-17 14:33:09,963][0m Trial 13 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.981642020448935, 'gae_lambda': 0.9193968352375892, 'learning_rate': 9.633905536228777e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 8, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 174      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -12.9       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 2           |
|    time_elapsed         | 401         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.000553009 |
|    clip_fraction        | 0.022       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | 6.55e-05    |
|    learning_rate        | 9.63e-05    |
|    loss                 | 0.661       |
|    n_updates            | 8           |
|    policy_gradient_loss | 1.16e-05    |
|    std                  | 0.998       |
|    value_loss           | 0.939       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-8.38 +/- 3.49
Episode length: 50.00 +/- 0.00
Success rate: 20.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -8.38         |
|    success_rate         | 0.2           |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00082042057 |
|    clip_fraction        | 0.0482        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -7.87e-06     |
|    learning_rate        | 9.63e-05      |
|    loss                 | 0.684         |
|    n_updates            | 16            |
|    policy_gradient_loss | -0.00104      |
|    std                  | 0.996         |
|    value_loss           | 1.1           |
-------------------------------------------
New best mean reward!
Elapsed time: 539.4711 seconds
[32m[I 2022-04-17 14:42:09,711][0m Trial 14 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9403540543104981, 'gae_lambda': 0.8691919821489563, 'learning_rate': 1.3447770320813202e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.5         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 419           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00079052144 |
|    clip_fraction        | 0.0527        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | -0.016        |
|    learning_rate        | 1.34e-05      |
|    loss                 | 0.273         |
|    n_updates            | 12            |
|    policy_gradient_loss | -0.00171      |
|    std                  | 1             |
|    value_loss           | 0.35          |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.62 +/- 2.94
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -9.62         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00055131334 |
|    clip_fraction        | 0.0305        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.00197       |
|    learning_rate        | 1.34e-05      |
|    loss                 | 0.228         |
|    n_updates            | 24            |
|    policy_gradient_loss | -0.00101      |
|    std                  | 1             |
|    value_loss           | 0.335         |
-------------------------------------------
New best mean reward!
Elapsed time: 575.9074 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 675      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 4            |
|    time_elapsed         | 917          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0006461544 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.0255       |
|    learning_rate        | 1.34e-05     |
|    loss                 | 0.161        |
|    n_updates            | 36           |
|    policy_gradient_loss | -0.00104     |
|    std                  | 0.999        |
|    value_loss           | 0.249        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 983.4195 seconds
[32m[I 2022-04-17 14:58:33,132][0m Trial 15 finished with value: -9.622224499999998 and parameters: {'gamma': 0.9403540543104981, 'gae_lambda': 0.8691919821489563, 'lr': 1.3447770320813202e-05, 'n_epochs': 12, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9207612851591356, 'gae_lambda': 0.8329619862149849, 'learning_rate': 0.0011153606401821746, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    fps             | 43       |
|    iterations      | 1        |
|    time_elapsed    | 187      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.6        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 419          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0011542556 |
|    clip_fraction        | 0.105        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | -0.0013      |
|    learning_rate        | 0.00112      |
|    loss                 | 0.153        |
|    n_updates            | 9            |
|    policy_gradient_loss | -0.000339    |
|    std                  | 0.996        |
|    value_loss           | 0.204        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.58 +/- 3.60
Episode length: 50.00 +/- 0.00
Success rate: 10.00%
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50         |
|    mean_reward          | -8.58      |
|    success_rate         | 0.1        |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.00108168 |
|    clip_fraction        | 0.0922     |
|    clip_range           | 0.075      |
|    entropy_loss         | -4.24      |
|    explained_variance   | 0          |
|    learning_rate        | 0.00112    |
|    loss                 | 0.136      |
|    n_updates            | 18         |
|    policy_gradient_loss | -0.000463  |
|    std                  | 0.994      |
|    value_loss           | 0.201      |
----------------------------------------
New best mean reward!
Elapsed time: 567.5984 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 671      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.6        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 907          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0006842853 |
|    clip_fraction        | 0.0929       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00112      |
|    loss                 | 0.122        |
|    n_updates            | 27           |
|    policy_gradient_loss | 8.78e-06     |
|    std                  | 0.99         |
|    value_loss           | 0.15         |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 958.4789 seconds
[32m[I 2022-04-17 15:14:31,612][0m Trial 16 finished with value: -8.5802454 and parameters: {'gamma': 0.9207612851591356, 'gae_lambda': 0.8329619862149849, 'lr': 0.0011153606401821746, 'n_epochs': 9, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9810938015916275, 'gae_lambda': 0.8789448329219297, 'learning_rate': 0.0001324534689298689, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 7, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64], 'vf': [64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 2            |
|    time_elapsed         | 397          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006234867 |
|    clip_fraction        | 0.0352       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.0147      |
|    learning_rate        | 0.000132     |
|    loss                 | 0.448        |
|    n_updates            | 7            |
|    policy_gradient_loss | -0.000649    |
|    std                  | 0.997        |
|    value_loss           | 0.584        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-10.39 +/- 2.76
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -10.4        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006407956 |
|    clip_fraction        | 0.0331       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | -0.00157     |
|    learning_rate        | 0.000132     |
|    loss                 | 0.36         |
|    n_updates            | 14           |
|    policy_gradient_loss | -0.00104     |
|    std                  | 0.993        |
|    value_loss           | 0.534        |
------------------------------------------
New best mean reward!
Elapsed time: 534.2394 seconds
[32m[I 2022-04-17 15:23:26,127][0m Trial 17 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.930886093495859, 'gae_lambda': 0.9128889912870946, 'learning_rate': 0.0006203511731340353, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13.1    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.6         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 415           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00079141586 |
|    clip_fraction        | 0.0722        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | -0.00627      |
|    learning_rate        | 0.00062       |
|    loss                 | 0.382         |
|    n_updates            | 11            |
|    policy_gradient_loss | -0.000147     |
|    std                  | 0.999         |
|    value_loss           | 0.486         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.16 +/- 4.48
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -9.16         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00082101603 |
|    clip_fraction        | 0.0711        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.24         |
|    explained_variance   | 0             |
|    learning_rate        | 0.00062       |
|    loss                 | 0.243         |
|    n_updates            | 22            |
|    policy_gradient_loss | -0.000786     |
|    std                  | 0.995         |
|    value_loss           | 0.358         |
-------------------------------------------
New best mean reward!
Elapsed time: 569.9385 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 672      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 4            |
|    time_elapsed         | 915          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0004894835 |
|    clip_fraction        | 0.042        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.00062      |
|    loss                 | 0.228        |
|    n_updates            | 33           |
|    policy_gradient_loss | 0.000256     |
|    std                  | 0.995        |
|    value_loss           | 0.299        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 977.8633 seconds
[32m[I 2022-04-17 15:39:43,992][0m Trial 18 finished with value: -9.1578877 and parameters: {'gamma': 0.930886093495859, 'gae_lambda': 0.9128889912870946, 'lr': 0.0006203511731340353, 'n_epochs': 11, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9699299916647021, 'gae_lambda': 0.8984346303110946, 'learning_rate': 0.008217504869769921, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 14, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 174      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 426          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0113436375 |
|    clip_fraction        | 0.594        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.27        |
|    explained_variance   | 0.0103       |
|    learning_rate        | 0.00822      |
|    loss                 | 0.467        |
|    n_updates            | 14           |
|    policy_gradient_loss | 0.0331       |
|    std                  | 0.996        |
|    value_loss           | 0.607        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-13.08 +/- 2.25
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -13.1        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0110960975 |
|    clip_fraction        | 0.582        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.00822      |
|    loss                 | 0.36         |
|    n_updates            | 28           |
|    policy_gradient_loss | 0.0269       |
|    std                  | 1            |
|    value_loss           | 0.48         |
------------------------------------------
New best mean reward!
Elapsed time: 593.4374 seconds
[32m[I 2022-04-17 15:49:37,703][0m Trial 19 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9494727431011006, 'gae_lambda': 0.9379481855287861, 'learning_rate': 7.149560528273725e-06, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64], 'vf': [64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 399          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007802684 |
|    clip_fraction        | 0.0299       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00786     |
|    learning_rate        | 7.15e-06     |
|    loss                 | 0.659        |
|    n_updates            | 9            |
|    policy_gradient_loss | -0.00116     |
|    std                  | 0.999        |
|    value_loss           | 1.63         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.02 +/- 2.81
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.02        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0001938498 |
|    clip_fraction        | 0            |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.00131     |
|    learning_rate        | 7.15e-06     |
|    loss                 | 0.557        |
|    n_updates            | 18           |
|    policy_gradient_loss | -0.000404    |
|    std                  | 0.999        |
|    value_loss           | 1.31         |
------------------------------------------
New best mean reward!
Elapsed time: 537.6316 seconds
[32m[I 2022-04-17 15:58:35,604][0m Trial 20 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9988986273401879, 'gae_lambda': 0.8012341921890312, 'learning_rate': 0.00016795361934264866, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 1        |
|    time_elapsed    | 173      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 413          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006451136 |
|    clip_fraction        | 0.0367       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00436     |
|    learning_rate        | 0.000168     |
|    loss                 | 0.166        |
|    n_updates            | 11           |
|    policy_gradient_loss | -0.000327    |
|    std                  | 1            |
|    value_loss           | 0.226        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.52 +/- 2.33
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -7.52        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006916786 |
|    clip_fraction        | 0.055        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.211        |
|    learning_rate        | 0.000168     |
|    loss                 | 0.154        |
|    n_updates            | 22           |
|    policy_gradient_loss | -0.00113     |
|    std                  | 0.997        |
|    value_loss           | 0.309        |
------------------------------------------
New best mean reward!
Elapsed time: 564.8169 seconds
[32m[I 2022-04-17 16:08:00,695][0m Trial 21 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9863322854171916, 'gae_lambda': 0.8252686219772498, 'learning_rate': 5.21105270269446e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 408          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007042102 |
|    clip_fraction        | 0.0576       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00249      |
|    learning_rate        | 5.21e-05     |
|    loss                 | 0.22         |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.00175     |
|    std                  | 0.997        |
|    value_loss           | 0.316        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.89 +/- 3.77
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -7.89        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006289743 |
|    clip_fraction        | 0.0422       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00798      |
|    learning_rate        | 5.21e-05     |
|    loss                 | 0.182        |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00114     |
|    std                  | 0.996        |
|    value_loss           | 0.263        |
------------------------------------------
New best mean reward!
Elapsed time: 550.7750 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 38       |
|    iterations      | 3        |
|    time_elapsed    | 645      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12           |
| time/                   |               |
|    fps                  | 37            |
|    iterations           | 4             |
|    time_elapsed         | 876           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00041230518 |
|    clip_fraction        | 0.0193        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.24         |
|    explained_variance   | 0.00996       |
|    learning_rate        | 5.21e-05      |
|    loss                 | 0.171         |
|    n_updates            | 30            |
|    policy_gradient_loss | -0.000432     |
|    std                  | 0.995         |
|    value_loss           | 0.278         |
-------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 930.1407 seconds
[32m[I 2022-04-17 16:23:30,836][0m Trial 22 finished with value: -7.8851637 and parameters: {'gamma': 0.9863322854171916, 'gae_lambda': 0.8252686219772498, 'lr': 5.21105270269446e-05, 'n_epochs': 10, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.987105836634313, 'gae_lambda': 0.8333812565491355, 'learning_rate': 4.969997868816388e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 47       |
|    iterations      | 1        |
|    time_elapsed    | 174      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12          |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 414          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0005770351 |
|    clip_fraction        | 0.0276       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.00299      |
|    learning_rate        | 4.97e-05     |
|    loss                 | 0.214        |
|    n_updates            | 12           |
|    policy_gradient_loss | -0.000526    |
|    std                  | 1            |
|    value_loss           | 0.294        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.84 +/- 2.93
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -8.84         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00066046184 |
|    clip_fraction        | 0.0387        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.0151        |
|    learning_rate        | 4.97e-05      |
|    loss                 | 0.209         |
|    n_updates            | 24            |
|    policy_gradient_loss | -0.000946     |
|    std                  | 0.998         |
|    value_loss           | 0.286         |
-------------------------------------------
New best mean reward!
Elapsed time: 573.5777 seconds
[32m[I 2022-04-17 16:33:04,737][0m Trial 23 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9599712495441949, 'gae_lambda': 0.8711920212953361, 'learning_rate': 1.8831709840276988e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -12.4       |
| time/                   |             |
|    fps                  | 40          |
|    iterations           | 2           |
|    time_elapsed         | 403         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.000666365 |
|    clip_fraction        | 0.0388      |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.26       |
|    explained_variance   | -0.00474    |
|    learning_rate        | 1.88e-05    |
|    loss                 | 0.265       |
|    n_updates            | 9           |
|    policy_gradient_loss | -0.00139    |
|    std                  | 0.999       |
|    value_loss           | 0.404       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-8.45 +/- 3.35
Episode length: 50.00 +/- 0.00
Success rate: 10.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.45        |
|    success_rate         | 0.1          |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0005756507 |
|    clip_fraction        | 0.0323       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.0298       |
|    learning_rate        | 1.88e-05     |
|    loss                 | 0.196        |
|    n_updates            | 18           |
|    policy_gradient_loss | -0.000953    |
|    std                  | 0.999        |
|    value_loss           | 0.359        |
------------------------------------------
New best mean reward!
Elapsed time: 541.9956 seconds
[32m[I 2022-04-17 16:42:07,196][0m Trial 24 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9767401149728219, 'gae_lambda': 0.8485882346252118, 'learning_rate': 7.98988222627466e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 412          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0008063214 |
|    clip_fraction        | 0.0592       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.00478      |
|    learning_rate        | 7.99e-05     |
|    loss                 | 0.248        |
|    n_updates            | 11           |
|    policy_gradient_loss | -0.00147     |
|    std                  | 1            |
|    value_loss           | 0.343        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.46 +/- 2.01
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -7.46         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00080423703 |
|    clip_fraction        | 0.0427        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -0.000983     |
|    learning_rate        | 7.99e-05      |
|    loss                 | 0.248         |
|    n_updates            | 22            |
|    policy_gradient_loss | -0.000823     |
|    std                  | 0.999         |
|    value_loss           | 0.321         |
-------------------------------------------
New best mean reward!
Elapsed time: 563.9034 seconds
[32m[I 2022-04-17 16:51:31,483][0m Trial 25 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9860006919375771, 'gae_lambda': 0.8247992511346689, 'learning_rate': 2.8356046194108232e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12           |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 416           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00061020936 |
|    clip_fraction        | 0.0349        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -0.0151       |
|    learning_rate        | 2.84e-05      |
|    loss                 | 0.222         |
|    n_updates            | 12            |
|    policy_gradient_loss | -0.000992     |
|    std                  | 0.998         |
|    value_loss           | 0.276         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-10.81 +/- 2.82
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -10.8        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006977498 |
|    clip_fraction        | 0.0351       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.0138       |
|    learning_rate        | 2.84e-05     |
|    loss                 | 0.175        |
|    n_updates            | 24           |
|    policy_gradient_loss | -0.00114     |
|    std                  | 0.996        |
|    value_loss           | 0.286        |
------------------------------------------
New best mean reward!
Elapsed time: 572.0308 seconds
[32m[I 2022-04-17 17:01:03,794][0m Trial 26 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9711770272485317, 'gae_lambda': 0.8788545504203726, 'learning_rate': 0.000593663108021595, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 7, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.8         |
| time/                   |               |
|    fps                  | 42            |
|    iterations           | 2             |
|    time_elapsed         | 390           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00077416317 |
|    clip_fraction        | 0.0863        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -0.0194       |
|    learning_rate        | 0.000594      |
|    loss                 | 0.366         |
|    n_updates            | 7             |
|    policy_gradient_loss | 0.000226      |
|    std                  | 0.994         |
|    value_loss           | 0.497         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.77 +/- 3.37
Episode length: 50.00 +/- 0.00
Success rate: 10.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.77        |
|    success_rate         | 0.1          |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006818538 |
|    clip_fraction        | 0.0514       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000594     |
|    loss                 | 0.285        |
|    n_updates            | 14           |
|    policy_gradient_loss | -0.000203    |
|    std                  | 0.991        |
|    value_loss           | 0.414        |
------------------------------------------
New best mean reward!
Elapsed time: 521.9182 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.3    |
| time/              |          |
|    fps             | 39       |
|    iterations      | 3        |
|    time_elapsed    | 623      |
|    total_timesteps | 24576    |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.3         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 4             |
|    time_elapsed         | 837           |
|    total_timesteps      | 32768         |
| train/                  |               |
|    approx_kl            | 0.00086822454 |
|    clip_fraction        | 0.0666        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.23         |
|    explained_variance   | -1.19e-07     |
|    learning_rate        | 0.000594      |
|    loss                 | 0.304         |
|    n_updates            | 21            |
|    policy_gradient_loss | -0.00054      |
|    std                  | 0.991         |
|    value_loss           | 0.385         |
-------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 876.7141 seconds
[32m[I 2022-04-17 17:15:40,510][0m Trial 27 finished with value: -8.7704346 and parameters: {'gamma': 0.9711770272485317, 'gae_lambda': 0.8788545504203726, 'lr': 0.000593663108021595, 'n_epochs': 7, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9918378353725682, 'gae_lambda': 0.8608634548892928, 'learning_rate': 0.00024220582832368474, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -13           |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 2             |
|    time_elapsed         | 403           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00077795936 |
|    clip_fraction        | 0.0434        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0.00868       |
|    learning_rate        | 0.000242      |
|    loss                 | 0.386         |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000469     |
|    std                  | 0.999         |
|    value_loss           | 0.496         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-10.81 +/- 2.87
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -10.8         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00086673803 |
|    clip_fraction        | 0.0682        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -2.79e-05     |
|    learning_rate        | 0.000242      |
|    loss                 | 0.347         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00166      |
|    std                  | 0.997         |
|    value_loss           | 0.513         |
-------------------------------------------
New best mean reward!
Elapsed time: 547.4232 seconds
[32m[I 2022-04-17 17:24:48,206][0m Trial 28 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9298039525443803, 'gae_lambda': 0.9258631984122534, 'learning_rate': 1.1441785450627723e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 7, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 174      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.3        |
| time/                   |              |
|    fps                  | 42           |
|    iterations           | 2            |
|    time_elapsed         | 388          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006456502 |
|    clip_fraction        | 0.0183       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.0413      |
|    learning_rate        | 1.14e-05     |
|    loss                 | 0.356        |
|    n_updates            | 7            |
|    policy_gradient_loss | -0.00104     |
|    std                  | 1            |
|    value_loss           | 0.481        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.99 +/- 2.85
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -8.99         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00074886857 |
|    clip_fraction        | 0.0172        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.0137        |
|    learning_rate        | 1.14e-05      |
|    loss                 | 0.298         |
|    n_updates            | 14            |
|    policy_gradient_loss | -0.000985     |
|    std                  | 0.999         |
|    value_loss           | 0.503         |
-------------------------------------------
New best mean reward!
Elapsed time: 518.7842 seconds
[32m[I 2022-04-17 17:33:27,261][0m Trial 29 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9743209097913712, 'gae_lambda': 0.96317522315002, 'learning_rate': 0.0003462137510352367, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.3        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 403          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0009113613 |
|    clip_fraction        | 0.074        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.000746     |
|    learning_rate        | 0.000346     |
|    loss                 | 1.38         |
|    n_updates            | 9            |
|    policy_gradient_loss | -0.000514    |
|    std                  | 0.998        |
|    value_loss           | 1.92         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-6.94 +/- 2.42
Episode length: 50.00 +/- 0.00
Success rate: 10.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -6.94         |
|    success_rate         | 0.1           |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00066680077 |
|    clip_fraction        | 0.0409        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | 0             |
|    learning_rate        | 0.000346      |
|    loss                 | 1.05          |
|    n_updates            | 18            |
|    policy_gradient_loss | -0.00062      |
|    std                  | 1             |
|    value_loss           | 1.79          |
-------------------------------------------
New best mean reward!
Elapsed time: 543.8622 seconds
[32m[I 2022-04-17 17:42:31,402][0m Trial 30 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9919727154300754, 'gae_lambda': 0.8120992971612615, 'learning_rate': 0.00018992537924022643, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 410          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006726112 |
|    clip_fraction        | 0.0554       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.0337      |
|    learning_rate        | 0.00019      |
|    loss                 | 0.188        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000766    |
|    std                  | 0.999        |
|    value_loss           | 0.266        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.10 +/- 3.56
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.1         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0007705343 |
|    clip_fraction        | 0.0481       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -2.98e-06    |
|    learning_rate        | 0.00019      |
|    loss                 | 0.163        |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.00107     |
|    std                  | 0.997        |
|    value_loss           | 0.276        |
------------------------------------------
New best mean reward!
Elapsed time: 555.2734 seconds
[32m[I 2022-04-17 17:51:46,955][0m Trial 31 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9916967726616441, 'gae_lambda': 0.8161689924305955, 'learning_rate': 8.953225682066496e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 8, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.6    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 2            |
|    time_elapsed         | 397          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006640926 |
|    clip_fraction        | 0.0434       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.0104      |
|    learning_rate        | 8.95e-05     |
|    loss                 | 0.206        |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.00104     |
|    std                  | 0.996        |
|    value_loss           | 0.279        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.08 +/- 2.31
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.08        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006361399 |
|    clip_fraction        | 0.0328       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0.0244       |
|    learning_rate        | 8.95e-05     |
|    loss                 | 0.182        |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.000367    |
|    std                  | 0.995        |
|    value_loss           | 0.29         |
------------------------------------------
New best mean reward!
Elapsed time: 533.7539 seconds
[32m[I 2022-04-17 18:00:40,987][0m Trial 32 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9623920615164666, 'gae_lambda': 0.8381142354535709, 'learning_rate': 3.856879529784675e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.2         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 419           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00077873096 |
|    clip_fraction        | 0.0397        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | -0.00521      |
|    learning_rate        | 3.86e-05      |
|    loss                 | 0.159         |
|    n_updates            | 11            |
|    policy_gradient_loss | -0.00103      |
|    std                  | 1             |
|    value_loss           | 0.242         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.96 +/- 1.59
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -9.96         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00047421633 |
|    clip_fraction        | 0.0147        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.0125        |
|    learning_rate        | 3.86e-05      |
|    loss                 | 0.154         |
|    n_updates            | 22            |
|    policy_gradient_loss | -0.00063      |
|    std                  | 1             |
|    value_loss           | 0.287         |
-------------------------------------------
New best mean reward!
Elapsed time: 572.5100 seconds
[32m[I 2022-04-17 18:10:13,779][0m Trial 33 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9986265962128787, 'gae_lambda': 0.9001863578228394, 'learning_rate': 0.0001352009484343904, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.2         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 417           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00041018258 |
|    clip_fraction        | 0.0419        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | -0.0012       |
|    learning_rate        | 0.000135      |
|    loss                 | 0.626         |
|    n_updates            | 12            |
|    policy_gradient_loss | -0.000543     |
|    std                  | 1             |
|    value_loss           | 0.886         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.59 +/- 2.45
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.59        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0007886075 |
|    clip_fraction        | 0.0515       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00033      |
|    learning_rate        | 0.000135     |
|    loss                 | 0.576        |
|    n_updates            | 24           |
|    policy_gradient_loss | -0.00123     |
|    std                  | 0.999        |
|    value_loss           | 0.965        |
------------------------------------------
New best mean reward!
Elapsed time: 573.6595 seconds
[32m[I 2022-04-17 18:19:47,722][0m Trial 34 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9665260546494076, 'gae_lambda': 0.8102617233546012, 'learning_rate': 0.0003193187050249735, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.7    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 428          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007981254 |
|    clip_fraction        | 0.0712       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0.0296       |
|    learning_rate        | 0.000319     |
|    loss                 | 0.149        |
|    n_updates            | 13           |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.996        |
|    value_loss           | 0.215        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.89 +/- 2.40
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.89        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006064805 |
|    clip_fraction        | 0.0352       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | -0.00112     |
|    learning_rate        | 0.000319     |
|    loss                 | 0.139        |
|    n_updates            | 26           |
|    policy_gradient_loss | -0.000273    |
|    std                  | 0.994        |
|    value_loss           | 0.184        |
------------------------------------------
New best mean reward!
Elapsed time: 589.8395 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    fps             | 35       |
|    iterations      | 3        |
|    time_elapsed    | 688      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 35           |
|    iterations           | 4            |
|    time_elapsed         | 932          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0005623193 |
|    clip_fraction        | 0.0355       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | -6.16e-05    |
|    learning_rate        | 0.000319     |
|    loss                 | 0.158        |
|    n_updates            | 39           |
|    policy_gradient_loss | -0.000145    |
|    std                  | 0.993        |
|    value_loss           | 0.191        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 1002.2063 seconds
[32m[I 2022-04-17 18:36:29,929][0m Trial 35 finished with value: -9.888820800000001 and parameters: {'gamma': 0.9665260546494076, 'gae_lambda': 0.8102617233546012, 'lr': 0.0003193187050249735, 'n_epochs': 13, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9471705261189121, 'gae_lambda': 0.8264618090723279, 'learning_rate': 6.658210231345562e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 14, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    fps             | 44       |
|    iterations      | 1        |
|    time_elapsed    | 184      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 37           |
|    iterations           | 2            |
|    time_elapsed         | 433          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007835615 |
|    clip_fraction        | 0.0415       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.0176       |
|    learning_rate        | 6.66e-05     |
|    loss                 | 0.134        |
|    n_updates            | 14           |
|    policy_gradient_loss | -0.00121     |
|    std                  | 1            |
|    value_loss           | 0.198        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.70 +/- 3.85
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -8.7          |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00059827196 |
|    clip_fraction        | 0.0531        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.413         |
|    learning_rate        | 6.66e-05      |
|    loss                 | 0.112         |
|    n_updates            | 28            |
|    policy_gradient_loss | -0.00187      |
|    std                  | 1             |
|    value_loss           | 0.149         |
-------------------------------------------
New best mean reward!
Elapsed time: 598.8610 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.9    |
| time/              |          |
|    fps             | 35       |
|    iterations      | 3        |
|    time_elapsed    | 696      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12          |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 4            |
|    time_elapsed         | 952          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0008546388 |
|    clip_fraction        | 0.0807       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.526        |
|    learning_rate        | 6.66e-05     |
|    loss                 | 0.148        |
|    n_updates            | 42           |
|    policy_gradient_loss | -0.0025      |
|    std                  | 0.998        |
|    value_loss           | 0.167        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 1027.2346 seconds
[32m[I 2022-04-17 18:53:37,165][0m Trial 36 finished with value: -8.6994601 and parameters: {'gamma': 0.9471705261189121, 'gae_lambda': 0.8264618090723279, 'lr': 6.658210231345562e-05, 'n_epochs': 14, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9858019498026999, 'gae_lambda': 0.8589129607691213, 'learning_rate': 0.000650988587222257, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.8    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -11.9         |
| time/                   |               |
|    fps                  | 40            |
|    iterations           | 2             |
|    time_elapsed         | 404           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00077838125 |
|    clip_fraction        | 0.0636        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -0.00874      |
|    learning_rate        | 0.000651      |
|    loss                 | 0.28          |
|    n_updates            | 10            |
|    policy_gradient_loss | -0.000509     |
|    std                  | 0.997         |
|    value_loss           | 0.389         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.43 +/- 2.76
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.43        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0005304617 |
|    clip_fraction        | 0.0266       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000651     |
|    loss                 | 0.269        |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.000197    |
|    std                  | 0.996        |
|    value_loss           | 0.438        |
------------------------------------------
New best mean reward!
Elapsed time: 550.1490 seconds
[32m[I 2022-04-17 19:02:47,585][0m Trial 37 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9088808173398701, 'gae_lambda': 0.8002462897035274, 'learning_rate': 0.00320181372421228, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128], 'vf': [128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.1    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -11.8       |
| time/                   |             |
|    fps                  | 39          |
|    iterations           | 2           |
|    time_elapsed         | 410         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.002345006 |
|    clip_fraction        | 0.251       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | -0.00201    |
|    learning_rate        | 0.0032      |
|    loss                 | 0.104       |
|    n_updates            | 11          |
|    policy_gradient_loss | 0.00458     |
|    std                  | 0.998       |
|    value_loss           | 0.168       |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-9.60 +/- 2.96
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.6         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0012378609 |
|    clip_fraction        | 0.173        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 5.96e-08     |
|    learning_rate        | 0.0032       |
|    loss                 | 0.0875       |
|    n_updates            | 22           |
|    policy_gradient_loss | 0.00189      |
|    std                  | 0.999        |
|    value_loss           | 0.128        |
------------------------------------------
New best mean reward!
Elapsed time: 563.1781 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.6    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 3        |
|    time_elapsed    | 661      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 898          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0028704253 |
|    clip_fraction        | 0.186        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0            |
|    learning_rate        | 0.0032       |
|    loss                 | 0.077        |
|    n_updates            | 33           |
|    policy_gradient_loss | 0.00268      |
|    std                  | 1            |
|    value_loss           | 0.117        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 957.6752 seconds
[32m[I 2022-04-17 19:18:45,261][0m Trial 38 finished with value: -9.6024642 and parameters: {'gamma': 0.9088808173398701, 'gae_lambda': 0.8002462897035274, 'lr': 0.00320181372421228, 'n_epochs': 11, 'net_arch_width_int': 7, 'net_arch_depth': 3}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9785387141603199, 'gae_lambda': 0.8389968235588944, 'learning_rate': 0.00022103460289975272, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 177      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 423          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0007117056 |
|    clip_fraction        | 0.0371       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.000692    |
|    learning_rate        | 0.000221     |
|    loss                 | 0.219        |
|    n_updates            | 13           |
|    policy_gradient_loss | -0.000422    |
|    std                  | 1            |
|    value_loss           | 0.281        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-6.76 +/- 2.42
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -6.76        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006735829 |
|    clip_fraction        | 0.0347       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000221     |
|    loss                 | 0.201        |
|    n_updates            | 26           |
|    policy_gradient_loss | -0.000696    |
|    std                  | 1            |
|    value_loss           | 0.287        |
------------------------------------------
New best mean reward!
Elapsed time: 584.6406 seconds
[32m[I 2022-04-17 19:28:30,343][0m Trial 39 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9926978886225348, 'gae_lambda': 0.8813651554114093, 'learning_rate': 3.350843686177892e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 175      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 409          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0005092705 |
|    clip_fraction        | 0.0281       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00254     |
|    learning_rate        | 3.35e-05     |
|    loss                 | 0.415        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000752    |
|    std                  | 1            |
|    value_loss           | 0.534        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.80 +/- 3.40
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.8         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006242719 |
|    clip_fraction        | 0.0272       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | 0.00389      |
|    learning_rate        | 3.35e-05     |
|    loss                 | 0.328        |
|    n_updates            | 20           |
|    policy_gradient_loss | -0.000746    |
|    std                  | 1            |
|    value_loss           | 0.593        |
------------------------------------------
New best mean reward!
Elapsed time: 556.5687 seconds
[32m[I 2022-04-17 19:37:47,191][0m Trial 40 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9192506690102098, 'gae_lambda': 0.8294906321729174, 'learning_rate': 0.0011922212223802412, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12      |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 405          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0010477424 |
|    clip_fraction        | 0.115        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0.00146      |
|    learning_rate        | 0.00119      |
|    loss                 | 0.0985       |
|    n_updates            | 9            |
|    policy_gradient_loss | 0.000307     |
|    std                  | 0.995        |
|    value_loss           | 0.177        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.52 +/- 2.92
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.52        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0018821035 |
|    clip_fraction        | 0.106        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00119      |
|    loss                 | 0.118        |
|    n_updates            | 18           |
|    policy_gradient_loss | 0.000351     |
|    std                  | 0.989        |
|    value_loss           | 0.148        |
------------------------------------------
New best mean reward!
Elapsed time: 546.7111 seconds
[32m[I 2022-04-17 19:46:54,182][0m Trial 41 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9112719023405348, 'gae_lambda': 0.8170042961578846, 'learning_rate': 0.0009661121831150643, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.7    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 40           |
|    iterations           | 2            |
|    time_elapsed         | 409          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0013184586 |
|    clip_fraction        | 0.123        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.24        |
|    explained_variance   | 0.00173      |
|    learning_rate        | 0.000966     |
|    loss                 | 0.0962       |
|    n_updates            | 9            |
|    policy_gradient_loss | -0.000104    |
|    std                  | 0.994        |
|    value_loss           | 0.157        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.50 +/- 2.44
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.5         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0006784466 |
|    clip_fraction        | 0.0661       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | 1.19e-07     |
|    learning_rate        | 0.000966     |
|    loss                 | 0.102        |
|    n_updates            | 18           |
|    policy_gradient_loss | -0.000192    |
|    std                  | 0.989        |
|    value_loss           | 0.139        |
------------------------------------------
New best mean reward!
Elapsed time: 549.2999 seconds
[32m[I 2022-04-17 19:56:04,365][0m Trial 42 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9117869495767565, 'gae_lambda': 0.8446003332033353, 'learning_rate': 0.002767007792193512, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13      |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 179      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 411          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0014185365 |
|    clip_fraction        | 0.245        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.0185       |
|    learning_rate        | 0.00277      |
|    loss                 | 0.145        |
|    n_updates            | 10           |
|    policy_gradient_loss | 0.00475      |
|    std                  | 0.993        |
|    value_loss           | 0.224        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-8.90 +/- 2.56
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -8.9         |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0019281993 |
|    clip_fraction        | 0.198        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.00277      |
|    loss                 | 0.169        |
|    n_updates            | 20           |
|    policy_gradient_loss | 0.0027       |
|    std                  | 0.99         |
|    value_loss           | 0.203        |
------------------------------------------
New best mean reward!
Elapsed time: 555.8271 seconds
[32m[I 2022-04-17 20:05:20,543][0m Trial 43 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9341202527774741, 'gae_lambda': 0.8206127107106356, 'learning_rate': 0.00042453048700611334, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 8, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 178      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.4        |
| time/                   |              |
|    fps                  | 41           |
|    iterations           | 2            |
|    time_elapsed         | 397          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0008038528 |
|    clip_fraction        | 0.0789       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -0.0506      |
|    learning_rate        | 0.000425     |
|    loss                 | 0.11         |
|    n_updates            | 8            |
|    policy_gradient_loss | -0.000812    |
|    std                  | 0.998        |
|    value_loss           | 0.16         |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-9.88 +/- 2.89
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -9.88        |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0007055196 |
|    clip_fraction        | 0.0572       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | -1.79e-05    |
|    learning_rate        | 0.000425     |
|    loss                 | 0.138        |
|    n_updates            | 16           |
|    policy_gradient_loss | -0.000537    |
|    std                  | 0.997        |
|    value_loss           | 0.176        |
------------------------------------------
New best mean reward!
Elapsed time: 532.4660 seconds
[32m[I 2022-04-17 20:14:13,287][0m Trial 44 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9246313700029261, 'gae_lambda': 0.8584769284663931, 'learning_rate': 0.016489943518143955, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 9, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -11.7    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
----------------------------------------
| rollout/                |            |
|    ep_len_mean          | 50         |
|    ep_rew_mean          | -11.8      |
| time/                   |            |
|    fps                  | 40         |
|    iterations           | 2          |
|    time_elapsed         | 404        |
|    total_timesteps      | 16384      |
| train/                  |            |
|    approx_kl            | 0.03593654 |
|    clip_fraction        | 0.807      |
|    clip_range           | 0.075      |
|    entropy_loss         | -4.3       |
|    explained_variance   | -0.027     |
|    learning_rate        | 0.0165     |
|    loss                 | 0.236      |
|    n_updates            | 9          |
|    policy_gradient_loss | 0.101      |
|    std                  | 1.01       |
|    value_loss           | 0.446      |
----------------------------------------
Eval num_timesteps=20000, episode_reward=-29.47 +/- 5.04
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
----------------------------------------
| eval/                   |            |
|    mean_ep_length       | 50         |
|    mean_reward          | -29.5      |
|    success_rate         | 0          |
| time/                   |            |
|    total_timesteps      | 20000      |
| train/                  |            |
|    approx_kl            | 0.13192895 |
|    clip_fraction        | 0.809      |
|    clip_range           | 0.075      |
|    entropy_loss         | -4.34      |
|    explained_variance   | 5.96e-08   |
|    learning_rate        | 0.0165     |
|    loss                 | 0.293      |
|    n_updates            | 18         |
|    policy_gradient_loss | 0.0928     |
|    std                  | 1.06       |
|    value_loss           | 0.247      |
----------------------------------------
New best mean reward!
Elapsed time: 543.3985 seconds
[32m[I 2022-04-17 20:23:16,965][0m Trial 45 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9551765416899218, 'gae_lambda': 0.8083494176616155, 'learning_rate': 9.919899707138857e-05, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.8    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
-------------------------------------------
| rollout/                |               |
|    ep_len_mean          | 50            |
|    ep_rew_mean          | -12.2         |
| time/                   |               |
|    fps                  | 39            |
|    iterations           | 2             |
|    time_elapsed         | 418           |
|    total_timesteps      | 16384         |
| train/                  |               |
|    approx_kl            | 0.00057784107 |
|    clip_fraction        | 0.0375        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | -0.0866       |
|    learning_rate        | 9.92e-05      |
|    loss                 | 0.118         |
|    n_updates            | 11            |
|    policy_gradient_loss | -0.000437     |
|    std                  | 1             |
|    value_loss           | 0.165         |
-------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.88 +/- 2.09
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -7.88         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00064170064 |
|    clip_fraction        | 0.0401        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.25         |
|    explained_variance   | -3.74e-05     |
|    learning_rate        | 9.92e-05      |
|    loss                 | 0.132         |
|    n_updates            | 22            |
|    policy_gradient_loss | -0.001        |
|    std                  | 0.998         |
|    value_loss           | 0.205         |
-------------------------------------------
New best mean reward!
Elapsed time: 567.5685 seconds
[32m[I 2022-04-17 20:32:44,815][0m Trial 46 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9010257370229855, 'gae_lambda': 0.9040551571196584, 'learning_rate': 0.0008832367499754147, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128], 'vf': [128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -13      |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 38           |
|    iterations           | 2            |
|    time_elapsed         | 421          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0008605708 |
|    clip_fraction        | 0.0932       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00104      |
|    learning_rate        | 0.000883     |
|    loss                 | 0.285        |
|    n_updates            | 12           |
|    policy_gradient_loss | 0.00014      |
|    std                  | 1            |
|    value_loss           | 0.347        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.99 +/- 2.74
Episode length: 50.00 +/- 0.00
Success rate: 10.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -7.99        |
|    success_rate         | 0.1          |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0008857659 |
|    clip_fraction        | 0.0613       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -1.19e-07    |
|    learning_rate        | 0.000883     |
|    loss                 | 0.158        |
|    n_updates            | 24           |
|    policy_gradient_loss | 7.79e-05     |
|    std                  | 0.999        |
|    value_loss           | 0.232        |
------------------------------------------
New best mean reward!
Elapsed time: 575.3861 seconds
[32m[I 2022-04-17 20:42:20,477][0m Trial 47 pruned. [0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9448113946298677, 'gae_lambda': 0.8674183187315612, 'learning_rate': 0.0001380428980272969, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 10, 'policy_kwargs': {'net_arch': [{'pi': [128, 128, 128, 128], 'vf': [128, 128, 128, 128]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 181      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 414          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006110545 |
|    clip_fraction        | 0.0414       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.00604     |
|    learning_rate        | 0.000138     |
|    loss                 | 0.255        |
|    n_updates            | 10           |
|    policy_gradient_loss | -0.000237    |
|    std                  | 1            |
|    value_loss           | 0.336        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-7.98 +/- 2.89
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-------------------------------------------
| eval/                   |               |
|    mean_ep_length       | 50            |
|    mean_reward          | -7.98         |
|    success_rate         | 0             |
| time/                   |               |
|    total_timesteps      | 20000         |
| train/                  |               |
|    approx_kl            | 0.00066387554 |
|    clip_fraction        | 0.0504        |
|    clip_range           | 0.075         |
|    entropy_loss         | -4.26         |
|    explained_variance   | 0.0223        |
|    learning_rate        | 0.000138      |
|    loss                 | 0.176         |
|    n_updates            | 20            |
|    policy_gradient_loss | -0.00139      |
|    std                  | 0.998         |
|    value_loss           | 0.255         |
-------------------------------------------
New best mean reward!
Elapsed time: 561.0322 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.7    |
| time/              |          |
|    fps             | 37       |
|    iterations      | 3        |
|    time_elapsed    | 661      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.4        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 898          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0005225986 |
|    clip_fraction        | 0.0436       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.0289       |
|    learning_rate        | 0.000138     |
|    loss                 | 0.191        |
|    n_updates            | 30           |
|    policy_gradient_loss | -0.00102     |
|    std                  | 0.997        |
|    value_loss           | 0.236        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 952.7205 seconds
[32m[I 2022-04-17 20:58:13,199][0m Trial 48 finished with value: -7.9830181 and parameters: {'gamma': 0.9448113946298677, 'gae_lambda': 0.8674183187315612, 'lr': 0.0001380428980272969, 'n_epochs': 10, 'net_arch_width_int': 7, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9431121589879127, 'gae_lambda': 0.8880108512932846, 'learning_rate': 0.00012136277664823008, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 11, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  SqueezeNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.5    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 180      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.9        |
| time/                   |              |
|    fps                  | 39           |
|    iterations           | 2            |
|    time_elapsed         | 416          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0006318069 |
|    clip_fraction        | 0.0477       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.26        |
|    explained_variance   | -0.0171      |
|    learning_rate        | 0.000121     |
|    loss                 | 0.213        |
|    n_updates            | 11           |
|    policy_gradient_loss | -0.00144     |
|    std                  | 0.999        |
|    value_loss           | 0.345        |
------------------------------------------
Eval num_timesteps=20000, episode_reward=-11.02 +/- 1.59
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
------------------------------------------
| eval/                   |              |
|    mean_ep_length       | 50           |
|    mean_reward          | -11          |
|    success_rate         | 0            |
| time/                   |              |
|    total_timesteps      | 20000        |
| train/                  |              |
|    approx_kl            | 0.0005115599 |
|    clip_fraction        | 0.0327       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 7.87e-06     |
|    learning_rate        | 0.000121     |
|    loss                 | 0.206        |
|    n_updates            | 22           |
|    policy_gradient_loss | -0.000882    |
|    std                  | 0.995        |
|    value_loss           | 0.311        |
------------------------------------------
New best mean reward!
Elapsed time: 566.6184 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning: The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.
  warnings.warn(
---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.3    |
| time/              |          |
|    fps             | 36       |
|    iterations      | 3        |
|    time_elapsed    | 669      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.1        |
| time/                   |              |
|    fps                  | 36           |
|    iterations           | 4            |
|    time_elapsed         | 905          |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0007776031 |
|    clip_fraction        | 0.0437       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.23        |
|    explained_variance   | 0            |
|    learning_rate        | 0.000121     |
|    loss                 | 0.217        |
|    n_updates            | 33           |
|    policy_gradient_loss | -0.00117     |
|    std                  | 0.99         |
|    value_loss           | 0.304        |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 963.9837 seconds
[32m[I 2022-04-17 21:14:17,184][0m Trial 49 finished with value: -11.0230052 and parameters: {'gamma': 0.9431121589879127, 'gae_lambda': 0.8880108512932846, 'lr': 0.00012136277664823008, 'n_epochs': 11, 'net_arch_width_int': 6, 'net_arch_depth': 4}. Best is trial 12 with value: -6.4980716.[0m

 

Number of finished trials:  50
Best trial:
  Value:  -6.4980716
  Params: 
    gamma: 0.992601496741308
    gae_lambda: 0.8789552297223628
    lr: 0.0001678993231767122
    n_epochs: 11
    net_arch_width_int: 7
    net_arch_depth: 4
  User attrs:
    vf_coef: 0.75
    clip_range: 0.075
    max_grad_norm: 0.5
    batch_size: 256
    n_steps: 2048
    ent_coef: 1e-06
    net_arch_width: 128
[32m[I 2022-04-17 21:14:23,904][0m A new study created in memory with name: no-name-d6b4f883-adba-4896-af92-9c21a5ae3014[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9538029043106557, 'gae_lambda': 0.981158578884362, 'learning_rate': 0.004735092551171188, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 13, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64], 'vf': [64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  ResNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning:

The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.

---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.9    |
| time/              |          |
|    fps             | 46       |
|    iterations      | 1        |
|    time_elapsed    | 176      |
|    total_timesteps | 8192     |
---------------------------------
-----------------------------------------
| rollout/                |             |
|    ep_len_mean          | 50          |
|    ep_rew_mean          | -12.5       |
| time/                   |             |
|    fps                  | 33          |
|    iterations           | 2           |
|    time_elapsed         | 485         |
|    total_timesteps      | 16384       |
| train/                  |             |
|    approx_kl            | 0.001120067 |
|    clip_fraction        | 0.188       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.26       |
|    explained_variance   | 0.00123     |
|    learning_rate        | 0.00474     |
|    loss                 | 1.72        |
|    n_updates            | 13          |
|    policy_gradient_loss | 0.00278     |
|    std                  | 1           |
|    value_loss           | 2.26        |
-----------------------------------------
Eval num_timesteps=20000, episode_reward=-9.95 +/- 3.25
Episode length: 50.00 +/- 0.00
Success rate: 0.00%
-----------------------------------------
| eval/                   |             |
|    mean_ep_length       | 50          |
|    mean_reward          | -9.95       |
|    success_rate         | 0           |
| time/                   |             |
|    total_timesteps      | 20000       |
| train/                  |             |
|    approx_kl            | 0.002499922 |
|    clip_fraction        | 0.178       |
|    clip_range           | 0.075       |
|    entropy_loss         | -4.25       |
|    explained_variance   | 0           |
|    learning_rate        | 0.00474     |
|    loss                 | 0.939       |
|    n_updates            | 26          |
|    policy_gradient_loss | 0.00285     |
|    std                  | 0.995       |
|    value_loss           | 1.31        |
-----------------------------------------
New best mean reward!
Elapsed time: 707.1952 seconds
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning:

The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.

---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.2    |
| time/              |          |
|    fps             | 30       |
|    iterations      | 3        |
|    time_elapsed    | 807      |
|    total_timesteps | 24576    |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -12.2        |
| time/                   |              |
|    fps                  | 29           |
|    iterations           | 4            |
|    time_elapsed         | 1117         |
|    total_timesteps      | 32768        |
| train/                  |              |
|    approx_kl            | 0.0017272774 |
|    clip_fraction        | 0.216        |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0            |
|    learning_rate        | 0.00474      |
|    loss                 | 1.03         |
|    n_updates            | 39           |
|    policy_gradient_loss | 0.00399      |
|    std                  | 0.995        |
|    value_loss           | 1.25         |
------------------------------------------
TRIAL Finished: Objective Trial Time
Elapsed time: 1246.4458 seconds
[32m[I 2022-04-17 21:35:10,351][0m Trial 0 finished with value: -9.945308800000001 and parameters: {'gamma': 0.9538029043106557, 'gae_lambda': 0.981158578884362, 'lr': 0.004735092551171188, 'n_epochs': 13, 'net_arch_width_int': 6, 'net_arch_depth': 3}. Best is trial 0 with value: -9.945308800000001.[0m

 

{'policy': 'CnnPolicy', 'device': 'cuda', 'verbose': 1, 'n_steps': 2048, 'gamma': 0.9552258164066861, 'gae_lambda': 0.8504609567774543, 'learning_rate': 0.0003052141182663456, 'ent_coef': 1e-06, 'max_grad_norm': 0.5, 'vf_coef': 0.75, 'clip_range': 0.075, 'batch_size': 256, 'n_epochs': 12, 'policy_kwargs': {'net_arch': [{'pi': [64, 64, 64, 64], 'vf': [64, 64, 64, 64]}], 'features_extractor_class': <class '__main__.PreBuiltCNN'>, 'features_extractor_kwargs': {'features_dim': 1000}}}
n_envs:  4

 

argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
argv[0]=--background_color_red=0.8745098039215686
argv[1]=
argv[2]=
argv[3]=
argv[4]=
argv[5]=
argv[6]=
argv[7]=
argv[8]=
argv[9]=
argv[10]=
argv[11]=
argv[12]=
argv[13]=
argv[14]=
argv[15]=
argv[16]=
argv[17]=
argv[18]=
argv[19]=
argv[20]=
argv[21]=--background_color_green=0.21176470588235294
argv[22]=
argv[23]=
argv[24]=
argv[25]=
argv[26]=
argv[27]=
argv[28]=
argv[29]=
argv[30]=
argv[31]=
argv[32]=
argv[33]=
argv[34]=
argv[35]=
argv[36]=
argv[37]=
argv[38]=
argv[39]=
argv[40]=
argv[41]=
argv[42]=--background_color_blue=0.17647058823529413
Using cuda device
network name:  ResNet
/home/hjkwon/scripts/stable_baselines/pandaAndrew/pybulletCust.py:94: UserWarning:

The use of the render method is not recommended when the environment has not been created with render=True. The rendering will probably be weird. Prefer making the environment with option `render=True`. For example: `env = gym.make('PandaReach-v2', render=True)`.

---------------------------------
| rollout/           |          |
|    ep_len_mean     | 50       |
|    ep_rew_mean     | -12.4    |
| time/              |          |
|    fps             | 45       |
|    iterations      | 1        |
|    time_elapsed    | 179      |
|    total_timesteps | 8192     |
---------------------------------
------------------------------------------
| rollout/                |              |
|    ep_len_mean          | 50           |
|    ep_rew_mean          | -11.8        |
| time/                   |              |
|    fps                  | 34           |
|    iterations           | 2            |
|    time_elapsed         | 477          |
|    total_timesteps      | 16384        |
| train/                  |              |
|    approx_kl            | 0.0010114076 |
|    clip_fraction        | 0.0756       |
|    clip_range           | 0.075        |
|    entropy_loss         | -4.25        |
|    explained_variance   | 0.00257      |
|    learning_rate        | 0.000305     |
|    loss                 | 0.0292       |
|    n_updates            | 12           |
|    policy_gradient_loss | -0.00193     |
|    std                  | 0.997        |
|    value_loss           | 0.131        |
------------------------------------------
^CTraceback (most recent call last):
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/mainOpt_V02.py", line 95, in <module>
    Plotter(study, Networks[network_i])
  File "/home/hjkwon/scripts/stable_baselines/pandaAndrew/optunaCust_V02.py", line 350, in Plotter
    fig3 = plot_param_importances(study)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/optuna/visualization/_param_importances.py", line 112, in plot_param_importances
    importances = optuna.importance.get_param_importances(
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/optuna/importance/__init__.py", line 93, in get_param_importances
    return evaluator.evaluate(study, params=params, target=target)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/optuna/importance/_fanova/_evaluator.py", line 87, in evaluate
    distributions = _get_distributions(study, params)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/optuna/importance/_base.py", line 69, in _get_distributions
    _check_evaluate_args(study, params)
  File "/home/hjkwon/anaconda3/envs/rl_env/lib/python3.9/site-packages/optuna/importance/_base.py", line 118, in _check_evaluate_args
    raise ValueError("Cannot evaluate parameter importances with only a single trial.")
ValueError: Cannot evaluate parameter importances with only a single trial.
(rl_env) ]0;hjkwon@HJK-AI-Robotics: ~/scripts/stable_baselines/pandaAndrew[01;32mhjkwon@HJK-AI-Robotics[00m:[01;34m~/scripts/stable_baselines/pandaAndrew[00m$ exit
exit

Script done on 2022-04-17 21:56:45-04:00 [COMMAND_EXIT_CODE="1"]
